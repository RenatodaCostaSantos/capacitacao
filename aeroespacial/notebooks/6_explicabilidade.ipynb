{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Explicabilidade\n",
    "\n",
    "Os gráficos SHAP (SHapley Additive exPlanations) são uma boa forma de visualizar a importancia das features utilizadas e tirar insights de como as features estão ajudando o modelo a prever o target.\n",
    "\n",
    "Plota-se abaixo alguns gráficos SHAP para se obter mais insights sobre as features e seu impacto na predição do target.\n",
    "\n",
    "Para plotar os gráficos abaixo, precisa-se dos seguintes artefatos gerados nos notebooks anteriores:\n",
    "\n",
    "- shap_values\n",
    "    - caminho: '../data/08_reporting/<nome_do_arquivo>.npy'\n",
    "\n",
    "- X_test_scaled\n",
    "    - caminho: '../data/03_primary/<nome_do_arquivo>.npy'\n",
    "\n",
    "- selected_features\n",
    "    - caminho: '../data/08_reporting/<nome_do_arquivo>.npy'\n",
    "\n",
    "- modelo\n",
    "    -  caminho: '../data/06_models/<nome_do_arquivo>.joblib'\n",
    "\n",
    "- explainer\n",
    "    - caminho: '../data/08_reporting/<nome_do_arquivo>.pkl'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import joblib  # Para salvar o modelo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shap\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selecionadas\n",
    "\n",
    "caminho_features_selecionadas_all_features = (\n",
    "    \"../data/08_reporting/selected_features_all_features.npy\"\n",
    ")\n",
    "\n",
    "caminho_features_selecionadas_non_linear_features = (\n",
    "    \"../data/08_reporting/selected_non_linear_features.npy\"\n",
    ")\n",
    "\n",
    "caminho_features_selecionadas_linear_features = (\n",
    "    \"../data/08_reporting/selected_linear_features.npy\"\n",
    ")\n",
    "\n",
    "# Caso os dvalores shapa já estejam calculados\n",
    "\n",
    "caminho_shap_all_features = (\n",
    "    \"../data/08_reporting/shap_values_calculados_all_features.npy\"\n",
    ")\n",
    "\n",
    "caminho_shap_non_linear_features = \"../data/08_reporting/shap_values_calculados.npy\"\n",
    "\n",
    "caminho_shap_linear_features = (\n",
    "    \"../data/08_reporting/shap_values_calculados_linear_features.npy\"\n",
    ")\n",
    "\n",
    "# Conjunto de treino normalizado para plotar o gráfico\n",
    "\n",
    "caminho_X_train_all_features = \"../data/03_primary/X_train_all_features.npy\"\n",
    "\n",
    "caminho_X_train_non_linear_features = (\n",
    "    \"../data/03_primary/X_train_non_linear_features.npy\"\n",
    ")\n",
    "\n",
    "caminho_X_train_linear_features = \"../data/03_primary/X_train_linear_features.npy\"\n",
    "\n",
    "# Target de treino normalizado\n",
    "\n",
    "caminho_y_train_all_features = \"../data/03_primary/y_train_all_features.npy\"\n",
    "\n",
    "caminho_y_train_non_linear_features = (\n",
    "    \"../data/03_primary/y_train_non_linear_features.npy\"\n",
    ")\n",
    "\n",
    "caminho_y_train_linear_features = \"../data/03_primary/y_train_linear_features.npy\"\n",
    "\n",
    "# Conjunto de teste normalizado para plotar o gráfico\n",
    "\n",
    "caminho_X_test_shap_all_features = (\n",
    "    \"../data/03_primary/X_test_final_para_shap_all_features.npy\"\n",
    ")\n",
    "\n",
    "caminho_X_test_shap_non_linear_features = (\n",
    "    \"../data/03_primary/X_test_final_para_shap.npy\"\n",
    ")\n",
    "\n",
    "caminho_X_test_shap_linear_features = (\n",
    "    \"../data/03_primary/X_test_final_para_shap_linear_features.npy\"\n",
    ")\n",
    "\n",
    "# Target de teste normalizado\n",
    "\n",
    "# caminho_y_teste_shap_all_features = '../data/03_primary/y_test_final_para_shap_all_features.npy'\n",
    "\n",
    "# caminho_y_teste_shap_non_linear_features = '../data/03_primary/y_test_final_para_shap.npy'\n",
    "\n",
    "# caminho_y_teste_shap_linear_features = '../data/03_primary/y_test_final_para_shap_linear_features.npy'\n",
    "\n",
    "caminho_y_teste_normalizado = \"../data/03_primary/y_teste_normalizado.npy\"\n",
    "\n",
    "# shap explainers\n",
    "\n",
    "caminho_explainer_all_features = (\n",
    "    \"../data/08_reporting/explainer_expected_value_all_features.pkl\"\n",
    ")\n",
    "\n",
    "caminho_explainer_non_linear_features = (\n",
    "    \"../data/08_reporting/explainer_expected_value.pkl\"\n",
    ")\n",
    "\n",
    "caminho_explainer_linear_features = (\n",
    "    \"../data/08_reporting/explainer_expected_value_linear_features.pkl\"\n",
    ")\n",
    "\n",
    "# modelos\n",
    "\n",
    "caminho_modelo_all_features = \"../data/06_models/modelo_notebook_2_all_data.joblib\"\n",
    "\n",
    "caminho_modelo_non_linear_features = \"../data/06_models/modelo_notebook_3.joblib\"\n",
    "\n",
    "caminho_modelo_linear_features = \"../data/06_models/modelo_notebook_4.joblib\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# 1 - Modelo com todas as features\n",
    "\n",
    "Carregando ou calculando artefatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_modelo_all_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: O modelo '{caminho_modelo_all_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # Carregamento dos dados necessários\n",
    "    X_test_scaled = np.load(caminho_X_test_shap_all_features, allow_pickle=True)\n",
    "    # y_test_scaled = np.load(caminho_y_teste_shap_all_features, allow_pickle=True)\n",
    "    y_test_scaled = np.load(caminho_y_teste_normalizado, allow_pickle=True)\n",
    "\n",
    "    # Carregamento dos nomes das features\n",
    "    with open(caminho_features_selecionadas_all_features, \"rb\") as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    selected_feature_names = loaded_data[\"list\"]\n",
    "\n",
    "    print(selected_feature_names)\n",
    "\n",
    "    # Carregamento do modelo (usando o caminho verificado)\n",
    "    best_nn_model = joblib.load(caminho_modelo_all_features)\n",
    "\n",
    "    # Verificação da existência dos SHAP Values e Expected Value (para evitar recálculo)\n",
    "    if os.path.exists(caminho_shap_all_features) and os.path.exists(\n",
    "        caminho_explainer_all_features\n",
    "    ):\n",
    "        print(\"Valores SHAP e Expected Value já existem. Carregando...\")\n",
    "\n",
    "        # Carregar os valores salvos\n",
    "        shap_values = np.load(caminho_shap_all_features, allow_pickle=True)\n",
    "\n",
    "        print(shap_values.shape)\n",
    "\n",
    "        # Carrega o Expected Value\n",
    "        with open(caminho_explainer_all_features, \"rb\") as f:\n",
    "            expected_value = pickle.load(f)\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            \"Valores SHAP e Expected Value não encontrados. Iniciando o cálculo demorado...\"\n",
    "        )\n",
    "\n",
    "        X_train_scaled = np.load(caminho_X_train_all_features, allow_pickle=True)\n",
    "\n",
    "        # O KernelExplainer usa um \"background dataset\"\n",
    "        X_background = shap.sample(X_train_scaled, 100)\n",
    "\n",
    "        # Cria o Explainer para calcular os valores\n",
    "        explainer = shap.KernelExplainer(best_nn_model.predict, X_background)\n",
    "\n",
    "        # Calcula os Valores SHAP\n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "        expected_value = explainer.expected_value  # Obtenha o valor base aqui\n",
    "\n",
    "        # SALVA OS VALORES (PARA EVITAR FUTUROS RECÁLCULOS)\n",
    "        np.save(caminho_shap_all_features, shap_values)\n",
    "\n",
    "        # Salva o Expected Value\n",
    "        with open(caminho_explainer_all_features, \"wb\") as f:\n",
    "            pickle.dump(expected_value, f)\n",
    "\n",
    "        print(\"Cálculo concluído. Valores SHAP e Expected Value salvos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_all_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_all_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    if isinstance(shap_values, list):\n",
    "        # Pega o primeiro elemento da lista\n",
    "        shap_values_array = shap_values[0]\n",
    "\n",
    "    else:\n",
    "        shap_values_array = shap_values\n",
    "\n",
    "    # ACHATA o array de (2000, 510, 1) para (2000, 510)\n",
    "    shap_values_plot = np.squeeze(shap_values_array)\n",
    "\n",
    "    # Verificação após o squeeze\n",
    "    print(f\"Novo Shape de shap_values_plot: {shap_values_plot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 1.1 - Gráfico de Resumo Global (Summary Plot - Importância das Features)\n",
    "\n",
    "Este é o gráfico mais importante e mostra a importância global das features.\n",
    "\n",
    "    - Eixo Y: Features ordenadas por importância.\n",
    "\n",
    "    - Eixo X: Valor SHAP.\n",
    "\n",
    "    - Cor: Valor da feature (azul = baixo valor da feature, vermelho = alto valor da feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_shap_summary(\n",
    "    shap_values=shap_values,\n",
    "    shap_values_plot=shap_values_plot,\n",
    "    X_test_scaled=X_test_scaled,\n",
    "    selected_feature_names=selected_feature_names,\n",
    "    title=\"Modelo com todas as features: Importância Global das Features\",\n",
    "    save_filename=\"../data/08_reporting/shap_summary_plot_all_features.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Explicação do gráfico acima\n",
    "\n",
    "O Gráfico de Resumo SHAP é a maneira mais concisa de entender a importância e a direção do impacto de cada feature nas previsões.\n",
    "\n",
    "\n",
    "- Eixo Y: Lista as features (variáveis de entrada), ordenadas da mais importante (topo) para a menos importante (base), com base na magnitude média dos seus valores SHAP.\n",
    "\n",
    "- Eixo X: Representa o Valor SHAP. Este valor indica a contribuição (positiva ou negativa) de uma feature para a previsão do modelo em relação ao valor de previsão base (média).\n",
    "\n",
    "- Cor do Ponto: Representa o valor real da feature para aquela observação. Geralmente, Vermelho = Alto Valor da Feature (Alto na escala escalada) e Azul = Baixo Valor da Feature (Baixo na escala escalada).\n",
    "\n",
    "- Dispersão dos Pontos,Cada ponto é uma observação individual do conjunto de teste. A dispersão horizontal mostra o quão variável é o impacto dessa feature entre as observações. Quanto maior a dispersão de uma feature que já foi avaliada como importante, maior é a interação entre as features do modelo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Significado Visual do Gráfico\n",
    "\n",
    "- Linha de Base: O ponto central, geralmente rotulado como E[f(x)] (o Valor Base/Média, 0.5108), é o ponto de partida da previsão.\n",
    "\n",
    "- Setas Vermelhas (Forças Positivas): Representam as features que estão aumentando o valor da previsão, empurrando-a para a direita em direção ao valor mais alto.\n",
    "\n",
    "- Setas Azuis (Forças Negativas): Representam as features que estão diminuindo o valor da previsão, empurrando-a para a esquerda em direção ao valor mais baixo.\n",
    "\n",
    "- Comprimento da Seta: Indica a magnitude do impacto daquela feature. Setas mais longas significam uma contribuição mais forte.\n",
    "\n",
    "### Interpretação dos Resultados da Observação 0\n",
    "\n",
    "A previsão de r (0.2748) é significativamente inferior ao valor médio (0.5108).\n",
    "\n",
    "Isto implica que, para esta observação específica, o modelo identificou que as características predominantes (setas azuis) puxaram a previsão para baixo, resultando em uma estimativa de r bem abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 1.2 - Gráfico de Força (Force Plot - Explicação Local)\n",
    "\n",
    "O gráfico abaixo explica uma única previsão. Ele mostra como cada feature empurra a previsão da linha de base (valor médio) para o valor final previsto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_all_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_all_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    observation_index = 0\n",
    "\n",
    "    utils.generate_shap_force_plot(\n",
    "        model=best_nn_model,\n",
    "        explainer_expected_value=expected_value,\n",
    "        shap_values_plot=shap_values_plot,\n",
    "        X_test_scaled=X_test_scaled,\n",
    "        selected_feature_names=selected_feature_names,\n",
    "        observation_index=observation_index,\n",
    "        save_filename_prefix=\"../data/08_reporting/shap_force_plot_all_features\",\n",
    "        dpi=300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Explicação do gráfico acima\n",
    "\n",
    "O Force Plot (Gráfico de Força) fornece uma explicação local, detalhando exatamente como cada feature da Observação 0 contribuiu para a previsão final do modelo.\n",
    "\n",
    "A observação 0 é a primeira linha do dataset.\n",
    "\n",
    "- Valor Base (Média): 0.4533,\n",
    "    - Significado: É a previsão média de r (ou a média dos targets escalados) para todo o conjunto de dados. Representa o ponto de partida do modelo antes de considerar as features específicas da observação.\n",
    "- Valor Previsto: 0.2599\n",
    "    - Significado: É o valor final previsto para r pelo modelo, após considerar todas as features específicas da Observação 0.\"\n",
    "\n",
    "## Significado Visual do Gráfico\n",
    "\n",
    "- Linha de Base: O ponto central, geralmente rotulado como E[f(x)] (o Valor Base/Média, 0.5108), é o ponto de partida da previsão.\n",
    "\n",
    "- Setas Vermelhas (Forças Positivas): Representam as features que estão aumentando o valor da previsão, empurrando-a para a direita em direção ao valor mais alto.\n",
    "\n",
    "- Setas Azuis (Forças Negativas): Representam as features que estão diminuindo o valor da previsão, empurrando-a para a esquerda em direção ao valor mais baixo.\n",
    "\n",
    "- Comprimento da Seta: Indica a magnitude do impacto daquela feature. Setas mais longas significam uma contribuição mais forte.\n",
    "\n",
    "## Interpretação dos Resultados da Observação 0\n",
    "\n",
    "A previsão de r (0.2599) é significativamente inferior ao valor médio (0.4533).\n",
    "\n",
    "Isto implica que, para esta observação específica, o modelo identificou que as características predominantes (setas azuis) puxaram a previsão para baixo, resultando em uma estimativa de r bem abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Observação\n",
    "\n",
    "- Um valor longe do valor médio, como mostrado no gráfico acima, não indica que o resultado foi ruim.\n",
    "\n",
    "- Podemos ver nas linhas de código abaixo que o valor `y_test_scaled`, que é o valor real normalizado, ficou próximo do valor normalizado previsto pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_y_teste_normalizado):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores normalizados de y contidos no caminho '{caminho_y_teste_normalizado}' não foram encontrados. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(y_test_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 1.3 - Gráfico de Dependência (Dependence Plot - Relação Feature-Target)\n",
    "\n",
    "O gráfico abaixo ajuda a entender a forma (linear ou não linear) da relação entre uma feature e o target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_all_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_all_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # Explicando a relação da feature mais importante\n",
    "    most_important_feature = \"l_120\"  # Substitua pelo nome da sua feature principal\n",
    "\n",
    "    shap.dependence_plot(\n",
    "        most_important_feature,\n",
    "        shap_values_plot,\n",
    "        X_test_scaled,\n",
    "        interaction_index=None,  # Não mostra interação com outra feature\n",
    "        show=False,\n",
    "        feature_names=selected_feature_names,\n",
    "    )\n",
    "    plt.title(f\"Impacto do {most_important_feature} no Resultado\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.savefig(\n",
    "        f\"../data/08_reporting/shap_dependence_plot_{most_important_feature}_all_features.png\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Explicação do gráfico acima\n",
    "\n",
    "- Eixo Y: Valor SHAP da Feature de interesse. Representa a contribuição real (o peso) que essa feature adiciona ou subtrai da previsão do modelo para aquela observação.\n",
    "- Eixo X: Valor Real da Feature de interesse. Mostra o valor escalado da variável.\n",
    "- Pontos: Cada ponto é uma observação individual do conjunto de teste.\n",
    "- Ausência de Cor: Com o interaction_index=None, os pontos não são coloridos por uma segunda feature. Eles refletem apenas a relação direta entre a feature de interesse e seu próprio impacto SHAP.\n",
    "\n",
    "## Como interpretar\n",
    "\n",
    "Ao analisar este gráfico, examina-se a forma da nuvem de pontos para entender a lógica do modelo.\n",
    "\n",
    "1. Relação Linear (Fácil de Interpretar)\n",
    "\n",
    "    Padrão: Os pontos formam uma linha reta ou tendem a seguir uma inclinação clara (seja positiva ou negativa).\n",
    "\n",
    "    Exemplo: Se, à medida que o valor da feature no Eixo X aumenta, o Valor SHAP no Eixo Y também aumenta (subindo da esquerda para a direita).\n",
    "\n",
    "    Conclusão: O modelo aprendeu uma relação linear simples: um aumento constante no valor da feature leva a um aumento constante na previsão.\n",
    "\n",
    "2. Relação Não Linear (Comum em Redes Neurais)\n",
    "\n",
    "    Padrão: Os pontos formam uma curva (ex: curva U, curva S invertida).\n",
    "\n",
    "    Exemplo: O Valor SHAP é baixo para valores extremos da feature (X baixo e X alto), mas o Valor SHAP se eleva significativamente para valores intermediários da feature.\n",
    "\n",
    "    Conclusão: O modelo aprendeu que o impacto da feature não é constante. Por exemplo, a variável é importante apenas dentro de um certo limite ótimo (o \"sweet spot\").\n",
    "\n",
    "3. Dispersão Vertical (Ruído e Interações Remotas)\n",
    "\n",
    "    Padrão: Em um valor específico no Eixo X (por exemplo, quando o valor da feature é 0.5), você vê os pontos dispersos verticalmente (ou seja, diferentes Valores SHAP).\n",
    "\n",
    "    Conclusão: Isso indica que, mesmo com o mesmo valor para a feature de interesse, seu impacto na previsão muda dependendo dos valores de outras features no modelo (as que você não está colorindo). O efeito é complexo e está sendo influenciado por interações de ordem superior que o modelo capturou.\n",
    "\n",
    "O Dependence Plot é uma ferramenta poderosa para validar se o modelo está aprendendo relações que fazem sentido no domínio do problema. Por exemplo, se uma relação linear é esperada e o gráfico mostra uma relação não linear, isso sugere que a Rede Neural descobriu uma dinâmica mais sutil nos dados. \n",
    "\n",
    "## Interpretação do gráfico gerado\n",
    "\n",
    "- O modelo aprendeu uma relação quase linear para essa feature, onde a contribuição marginal é mais significativa nas extremidades. Os Valores SHAP nulos na faixa intermediária da feature indicam que, nesse ponto, o efeito da feature sobre a previsão é neutro, ou seja, ele não contribui nem positivamente nem negativamente em relação à previsão média do modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# 2 - Modelo com seleção de features não linear\n",
    "\n",
    "Carregando ou calculando artefatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_modelo_non_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: O modelo '{caminho_modelo_non_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # Carregamento dos dados necessários\n",
    "    X_test_scaled = np.load(caminho_X_test_shap_non_linear_features, allow_pickle=True)\n",
    "    y_test_scaled = np.load(caminho_y_teste_normalizado, allow_pickle=True)\n",
    "\n",
    "    # Carregamento dos nomes das features\n",
    "    with open(caminho_features_selecionadas_non_linear_features, \"rb\") as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    selected_feature_names = loaded_data[\"list\"]\n",
    "\n",
    "    print(selected_feature_names.shape)\n",
    "\n",
    "    # Carregamento do modelo\n",
    "    best_nn_model = joblib.load(caminho_modelo_non_linear_features)\n",
    "\n",
    "    # Verificação da existência dos SHAP Values e Expected Value (para evitar recálculo)\n",
    "    if os.path.exists(caminho_shap_non_linear_features) and os.path.exists(\n",
    "        caminho_explainer_non_linear_features\n",
    "    ):\n",
    "        print(\"Valores SHAP e Expected Value já existem. Carregando...\")\n",
    "\n",
    "        # Carregar os valores salvos\n",
    "        shap_values = np.load(caminho_shap_non_linear_features, allow_pickle=True)\n",
    "\n",
    "        # Carregar o Expected Value\n",
    "        with open(caminho_explainer_non_linear_features, \"rb\") as f:\n",
    "            expected_value = pickle.load(f)\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            \"Valores SHAP e Expected Value não encontrados. Iniciando o cálculo demorado...\"\n",
    "        )\n",
    "\n",
    "        X_train_scaled = np.load(caminho_X_train_non_linear_features, allow_pickle=True)\n",
    "\n",
    "        # O KernelExplainer usa um \"background dataset\"\n",
    "        X_background = shap.sample(X_train_scaled, 100)\n",
    "\n",
    "        # Cria o Explainer para calcular os valores\n",
    "        explainer = shap.KernelExplainer(best_nn_model.predict, X_background)\n",
    "\n",
    "        # Calcula os Valores SHAP\n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "        expected_value = explainer.expected_value  # Obtenha o valor base aqui\n",
    "\n",
    "        # SALVA OS VALORES (PARA EVITAR FUTUROS RECÁLCULOS)\n",
    "        np.save(caminho_shap_non_linear_features, shap_values)\n",
    "\n",
    "        # Salvar o Expected Value\n",
    "        with open(caminho_explainer_non_linear_features, \"wb\") as f:\n",
    "            pickle.dump(expected_value, f)\n",
    "\n",
    "        print(\"Cálculo concluído. Valores SHAP e Expected Value salvos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_non_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_non_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    if isinstance(shap_values, list):\n",
    "        # Pega o primeiro elemento da lista\n",
    "        shap_values_array = shap_values[0]\n",
    "\n",
    "    else:\n",
    "        shap_values_array = shap_values\n",
    "\n",
    "    # ACHATA o array de (2000, 510, 1) para (2000, 510)\n",
    "    shap_values_plot = np.squeeze(shap_values_array)\n",
    "\n",
    "    # Verificação após o squeeze\n",
    "    print(f\"Novo Shape de shap_values_plot: {shap_values_plot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 2.1 - Gráfico de Resumo Global (Summary Plot - Importância das Features)\n",
    "\n",
    "Este é o gráfico mais importante e mostra a importância global das features.\n",
    "\n",
    "    - Eixo Y: Features ordenadas por importância.\n",
    "\n",
    "    - Eixo X: Valor SHAP.\n",
    "\n",
    "    - Cor: Valor da feature (azul = baixo valor da feature, vermelho = alto valor da feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_shap_summary(\n",
    "    shap_values=shap_values,\n",
    "    shap_values_plot=shap_values_plot,\n",
    "    X_test_scaled=X_test_scaled,\n",
    "    selected_feature_names=selected_feature_names,\n",
    "    title=\"Modelo com seleção linear de features: Importância Global das Features\",\n",
    "    save_filename=\"../data/08_reporting/shap_summary_plot_non_linear_features.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Explicação do gráfico acima\n",
    "\n",
    "O Gráfico de Resumo SHAP é a maneira mais concisa de entender a importância e a direção do impacto de cada feature nas previsões.\n",
    "\n",
    "\n",
    "- Eixo Y: Lista as features (variáveis de entrada), ordenadas da mais importante (topo) para a menos importante (base), com base na magnitude média dos seus valores SHAP.\n",
    "\n",
    "- Eixo X: Representa o Valor SHAP. Este valor indica a contribuição (positiva ou negativa) de uma feature para a previsão do modelo em relação ao valor de previsão base (média).\n",
    "\n",
    "- Cor do Ponto: Representa o valor real da feature para aquela observação. Geralmente, Vermelho = Alto Valor da Feature (Alto na escala escalada) e Azul = Baixo Valor da Feature (Baixo na escala escalada).\n",
    "\n",
    "- Dispersão dos Pontos,Cada ponto é uma observação individual do conjunto de teste. A dispersão horizontal mostra o quão variável é o impacto dessa feature entre as observações. Quanto maior a dispersão de uma feature que já foi avaliada como importante, maior é a interação entre as features do modelo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Significado Visual do Gráfico\n",
    "\n",
    "- Linha de Base: O ponto central, geralmente rotulado como E[f(x)] (o Valor Base/Média, 0.5108), é o ponto de partida da previsão.\n",
    "\n",
    "- Setas Vermelhas (Forças Positivas): Representam as features que estão aumentando o valor da previsão, empurrando-a para a direita em direção ao valor mais alto.\n",
    "\n",
    "- Setas Azuis (Forças Negativas): Representam as features que estão diminuindo o valor da previsão, empurrando-a para a esquerda em direção ao valor mais baixo.\n",
    "\n",
    "- Comprimento da Seta: Indica a magnitude do impacto daquela feature. Setas mais longas significam uma contribuição mais forte.\n",
    "\n",
    "### Interpretação dos Resultados da Observação 0\n",
    "\n",
    "A previsão de r (0.2748) é significativamente inferior ao valor médio (0.5108).\n",
    "\n",
    "Isto implica que, para esta observação específica, o modelo identificou que as características predominantes (setas azuis) puxaram a previsão para baixo, resultando em uma estimativa de r bem abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 2.2 - Gráfico de Força (Force Plot - Explicação Local)\n",
    "\n",
    "O gráfico abaixo explica uma única previsão. Ele mostra como cada feature empurra a previsão da linha de base (valor médio) para o valor final previsto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_non_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_non_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    observation_index = 0\n",
    "\n",
    "    utils.generate_shap_force_plot(\n",
    "        model=best_nn_model,\n",
    "        explainer_expected_value=expected_value,\n",
    "        shap_values_plot=shap_values_plot,\n",
    "        X_test_scaled=X_test_scaled,\n",
    "        selected_feature_names=selected_feature_names,\n",
    "        observation_index=observation_index,\n",
    "        save_filename_prefix=\"../data/08_reporting/shap_force_plot_non_linear_features\",\n",
    "        dpi=300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Explicação do gráfico acima\n",
    "\n",
    "O Force Plot (Gráfico de Força) fornece uma explicação local, detalhando exatamente como cada feature da Observação 0 contribuiu para a previsão final do modelo.\n",
    "\n",
    "A observação 0 é a primeira linha do dataset.\n",
    "\n",
    "- Valor Base (Média): 0.4457,\n",
    "    - Significado: É a previsão média de r (ou a média dos targets escalados) para todo o conjunto de dados. Representa o ponto de partida do modelo antes de considerar as features específicas da observação.\n",
    "- Valor Previsto: 0.2794\n",
    "    - Significado: É o valor final previsto para r pelo modelo, após considerar todas as features específicas da Observação 0.\"\n",
    "\n",
    "## Significado Visual do Gráfico\n",
    "\n",
    "- Linha de Base: O ponto central, geralmente rotulado como E[f(x)] (o Valor Base/Média, 0.4457), é o ponto de partida da previsão.\n",
    "\n",
    "- Setas Vermelhas (Forças Positivas): Representam as features que estão aumentando o valor da previsão, empurrando-a para a direita em direção ao valor mais alto.\n",
    "\n",
    "- Setas Azuis (Forças Negativas): Representam as features que estão diminuindo o valor da previsão, empurrando-a para a esquerda em direção ao valor mais baixo.\n",
    "\n",
    "- Comprimento da Seta: Indica a magnitude do impacto daquela feature. Setas mais longas significam uma contribuição mais forte.\n",
    "\n",
    "## Interpretação dos Resultados da Observação 0\n",
    "\n",
    "A previsão de r (0.2794) é significativamente inferior ao valor médio (0.4457).\n",
    "\n",
    "Isto implica que, para esta observação específica, o modelo identificou que as características predominantes (setas azuis) puxaram a previsão para baixo, resultando em uma estimativa de r bem abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Observação\n",
    "\n",
    "- Um valor longe do valor médio, como mostrado no gráfico acima, não indica que o resultado foi ruim.\n",
    "\n",
    "- Podemos ver nas linhas de código abaixo que o valor `y_test_scaled`, que é o valor real normalizado, ficou próximo do valor normalizado previsto pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_y_teste_normalizado):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores normalizados de y contidos no caminho '{caminho_y_teste_normalizado}' não foram encontrados. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(y_test_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## 2.3 - Gráfico de Dependência (Dependence Plot - Relação Feature-Target)\n",
    "\n",
    "O Gráfico de Dependência SHAP (SHAP Dependence Plot) é projetado para mostrar como a relação entre uma feature específica e o resultado do modelo se parece. Em essência, é uma versão explicável do tradicional gráfico de dispersão, ajudando a visualizar a forma (linear, não linear, ou complexa) que o modelo aprendeu para essa variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_non_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_non_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # Explicando a relação da feature mais importante\n",
    "    most_important_feature = selected_feature_names[\n",
    "        0\n",
    "    ]  # Substitua pelo nome da sua feature principal\n",
    "\n",
    "    shap.dependence_plot(\n",
    "        most_important_feature,\n",
    "        shap_values_plot,\n",
    "        X_test_scaled,\n",
    "        interaction_index=None,  # Não mostra interação com outra feature\n",
    "        show=False,\n",
    "        feature_names=selected_feature_names,\n",
    "    )\n",
    "    plt.title(f\"Impacto do {most_important_feature} no Resultado\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.savefig(\n",
    "        f\"../data/08_reporting/shap_dependence_plot_{most_important_feature}_non_linear_features.png\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Explicação do gráfico acima\n",
    "\n",
    "- Eixo Y: Valor SHAP da Feature de interesse. Representa a contribuição real (o peso) que essa feature adiciona ou subtrai da previsão do modelo para aquela observação.\n",
    "- Eixo X: Valor Real da Feature de interesse. Mostra o valor escalado da variável.\n",
    "- Pontos: Cada ponto é uma observação individual do conjunto de teste.\n",
    "- Ausência de Cor: Com o interaction_index=None, os pontos não são coloridos por uma segunda feature. Eles refletem apenas a relação direta entre a feature de interesse e seu próprio impacto SHAP.\n",
    "\n",
    "## Como interpretar\n",
    "\n",
    "Ao analisar este gráfico, examina-se a forma da nuvem de pontos para entender a lógica do modelo.\n",
    "\n",
    "1. Relação Linear (Fácil de Interpretar)\n",
    "\n",
    "    Padrão: Os pontos formam uma linha reta ou tendem a seguir uma inclinação clara (seja positiva ou negativa).\n",
    "\n",
    "    Exemplo: Se, à medida que o valor da feature no Eixo X aumenta, o Valor SHAP no Eixo Y também aumenta (subindo da esquerda para a direita).\n",
    "\n",
    "    Conclusão: O modelo aprendeu uma relação linear simples: um aumento constante no valor da feature leva a um aumento constante na previsão.\n",
    "\n",
    "2. Relação Não Linear (Comum em Redes Neurais)\n",
    "\n",
    "    Padrão: Os pontos formam uma curva (ex: curva U, curva S invertida).\n",
    "\n",
    "    Exemplo: O Valor SHAP é baixo para valores extremos da feature (X baixo e X alto), mas o Valor SHAP se eleva significativamente para valores intermediários da feature.\n",
    "\n",
    "    Conclusão: O modelo aprendeu que o impacto da feature não é constante. Por exemplo, a variável é importante apenas dentro de um certo limite ótimo (o \"sweet spot\").\n",
    "\n",
    "3. Dispersão Vertical (Ruído e Interações Remotas)\n",
    "\n",
    "    Padrão: Em um valor específico no Eixo X (por exemplo, quando o valor da feature é 0.5), você vê os pontos dispersos verticalmente (ou seja, diferentes Valores SHAP).\n",
    "\n",
    "    Conclusão: Isso indica que, mesmo com o mesmo valor para a feature de interesse, seu impacto na previsão muda dependendo dos valores de outras features no modelo (as que você não está colorindo). O efeito é complexo e está sendo influenciado por interações de ordem superior que o modelo capturou.\n",
    "\n",
    "O Dependence Plot é uma ferramenta poderosa para validar se o modelo está aprendendo relações que fazem sentido no domínio do problema. Por exemplo, se uma relação linear é esperada e o gráfico mostra uma relação não linear, isso sugere que a Rede Neural descobriu uma dinâmica mais sutil nos dados. \n",
    "\n",
    "## Interpretação do gráfico gerado\n",
    "\n",
    "- O modelo aprendeu uma relação quase linear para essa feature, onde a contribuição marginal é mais significativa nas extremidades. Os Valores SHAP nulos na faixa intermediária da feature indicam que, nesse ponto, o efeito da feature sobre a previsão é neutro, ou seja, ele não contribui nem positivamente nem negativamente em relação à previsão média do modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "# 3 - Modelo com seleção de features linear\n",
    "\n",
    "Carregando ou calculando artefatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_modelo_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: O modelo '{caminho_modelo_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # Carregamento dos dados necessários\n",
    "    X_test_scaled = np.load(caminho_X_test_shap_linear_features, allow_pickle=True)\n",
    "    y_test_scaled = np.load(caminho_y_teste_normalizado, allow_pickle=True)\n",
    "\n",
    "    # Carregamento dos nomes das features\n",
    "    with open(caminho_features_selecionadas_linear_features, \"rb\") as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    selected_feature_names = loaded_data[\"list\"]\n",
    "\n",
    "    print(selected_feature_names.shape)\n",
    "\n",
    "    # Carregamento do modelo (usando o caminho verificado)\n",
    "    best_nn_model = joblib.load(caminho_modelo_linear_features)\n",
    "\n",
    "    # Verificação da existência dos SHAP Values e Expected Value (para evitar recálculo)\n",
    "    if os.path.exists(caminho_shap_linear_features) and os.path.exists(\n",
    "        caminho_explainer_linear_features\n",
    "    ):\n",
    "        print(\"Valores SHAP e Expected Value já existem. Carregando...\")\n",
    "\n",
    "        # Carregar os valores salvos\n",
    "        shap_values = np.load(caminho_shap_linear_features, allow_pickle=True)\n",
    "\n",
    "        # Carregar o Expected Value (que você salvou)\n",
    "        with open(caminho_explainer_linear_features, \"rb\") as f:\n",
    "            expected_value = pickle.load(f)\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            \"Valores SHAP e Expected Value não encontrados. Iniciando o cálculo demorado...\"\n",
    "        )\n",
    "\n",
    "        X_train_scaled = np.load(caminho_X_train_linear_features, allow_pickle=True)\n",
    "\n",
    "        # O KernelExplainer usa um \"background dataset\"\n",
    "        X_background = shap.sample(X_train_scaled, 100)\n",
    "\n",
    "        # Cria o Explainer para calcular os valores\n",
    "        explainer = shap.KernelExplainer(best_nn_model.predict, X_background)\n",
    "\n",
    "        # Calcular os Valores SHAP\n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "        expected_value = explainer.expected_value  # Obtenha o valor base aqui\n",
    "\n",
    "        # SALVA OS VALORES (PARA EVITAR FUTUROS RECÁLCULOS)\n",
    "        np.save(caminho_shap_linear_features, shap_values)\n",
    "\n",
    "        # Salvar o Expected Value\n",
    "        with open(caminho_explainer_linear_features, \"wb\") as f:\n",
    "            pickle.dump(expected_value, f)\n",
    "\n",
    "        print(\"Cálculo concluído. Valores SHAP e Expected Value salvos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    if isinstance(shap_values, list):\n",
    "        # Pega o primeiro elemento da lista\n",
    "        shap_values_array = shap_values[0]\n",
    "\n",
    "    else:\n",
    "        shap_values_array = shap_values\n",
    "\n",
    "    # ACHATA o array de (2000, 510, 1) para (2000, 510)\n",
    "    shap_values_plot = np.squeeze(shap_values_array)\n",
    "\n",
    "    # Verificação após o squeeze\n",
    "    print(f\"Novo Shape de shap_values_plot: {shap_values_plot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## 3.1 - Gráfico de Resumo Global (Summary Plot - Importância das Features)\n",
    "\n",
    "Este é o gráfico mais importante e mostra a importância global das features.\n",
    "\n",
    "    - Eixo Y: Features ordenadas por importância.\n",
    "\n",
    "    - Eixo X: Valor SHAP.\n",
    "\n",
    "    - Cor: Valor da feature (azul = baixo valor da feature, vermelho = alto valor da feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_shap_summary(\n",
    "    shap_values=shap_values,\n",
    "    shap_values_plot=shap_values_plot,\n",
    "    X_test_scaled=X_test_scaled,\n",
    "    selected_feature_names=selected_feature_names,\n",
    "    title=\"Modelo com seleção linear de features: Importância Global das Features\",\n",
    "    save_filename=\"../data/08_reporting/shap_summary_plot_linear_features.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Explicação do gráfico acima\n",
    "\n",
    "O Gráfico de Resumo SHAP é a maneira mais concisa de entender a importância e a direção do impacto de cada feature nas previsões.\n",
    "\n",
    "\n",
    "- Eixo Y: Lista as features (variáveis de entrada), ordenadas da mais importante (topo) para a menos importante (base), com base na magnitude média dos seus valores SHAP.\n",
    "\n",
    "- Eixo X: Representa o Valor SHAP. Este valor indica a contribuição (positiva ou negativa) de uma feature para a previsão do modelo em relação ao valor de previsão base (média).\n",
    "\n",
    "- Cor do Ponto: Representa o valor real da feature para aquela observação. Geralmente, Vermelho = Alto Valor da Feature (Alto na escala escalada) e Azul = Baixo Valor da Feature (Baixo na escala escalada).\n",
    "\n",
    "- Dispersão dos Pontos,Cada ponto é uma observação individual do conjunto de teste. A dispersão horizontal mostra o quão variável é o impacto dessa feature entre as observações. Quanto maior a dispersão de uma feature que já foi avaliada como importante, maior é a interação entre as features do modelo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Significado Visual do Gráfico\n",
    "\n",
    "- Linha de Base: O ponto central, geralmente rotulado como E[f(x)] (o Valor Base/Média, 0.5108), é o ponto de partida da previsão.\n",
    "\n",
    "- Setas Vermelhas (Forças Positivas): Representam as features que estão aumentando o valor da previsão, empurrando-a para a direita em direção ao valor mais alto.\n",
    "\n",
    "- Setas Azuis (Forças Negativas): Representam as features que estão diminuindo o valor da previsão, empurrando-a para a esquerda em direção ao valor mais baixo.\n",
    "\n",
    "- Comprimento da Seta: Indica a magnitude do impacto daquela feature. Setas mais longas significam uma contribuição mais forte.\n",
    "\n",
    "### Interpretação dos Resultados da Observação 0\n",
    "\n",
    "A previsão de r (0.2748) é significativamente inferior ao valor médio (0.5108).\n",
    "\n",
    "Isto implica que, para esta observação específica, o modelo identificou que as características predominantes (setas azuis) puxaram a previsão para baixo, resultando em uma estimativa de r bem abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## 3.2 - Gráfico de Força (Force Plot - Explicação Local)\n",
    "\n",
    "O gráfico abaixo explica uma única previsão. Ele mostra como cada feature empurra a previsão da linha de base (valor médio) para o valor final previsto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    observation_index = 0\n",
    "\n",
    "    utils.generate_shap_force_plot(\n",
    "        model=best_nn_model,\n",
    "        explainer_expected_value=expected_value,\n",
    "        shap_values_plot=shap_values_plot,\n",
    "        X_test_scaled=X_test_scaled,\n",
    "        selected_feature_names=selected_feature_names,\n",
    "        observation_index=observation_index,\n",
    "        save_filename_prefix=\"../data/08_reporting/shap_force_plot_linear_features\",\n",
    "        dpi=300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## Explicação do gráfico acima\n",
    "\n",
    "O Force Plot (Gráfico de Força) fornece uma explicação local, detalhando exatamente como cada feature da Observação 0 contribuiu para a previsão final do modelo.\n",
    "\n",
    "A observação 0 é a primeira linha do dataset.\n",
    "\n",
    "- Valor Base (Média): 0.4533,\n",
    "    - Significado: É a previsão média de r (ou a média dos targets escalados) para todo o conjunto de dados. Representa o ponto de partida do modelo antes de considerar as features específicas da observação.\n",
    "- Valor Previsto: 0.2599\n",
    "    - Significado: É o valor final previsto para r pelo modelo, após considerar todas as features específicas da Observação 0.\"\n",
    "\n",
    "## Significado Visual do Gráfico\n",
    "\n",
    "- Linha de Base: O ponto central, geralmente rotulado como E[f(x)] (o Valor Base/Média, 0.5108), é o ponto de partida da previsão.\n",
    "\n",
    "- Setas Vermelhas (Forças Positivas): Representam as features que estão aumentando o valor da previsão, empurrando-a para a direita em direção ao valor mais alto.\n",
    "\n",
    "- Setas Azuis (Forças Negativas): Representam as features que estão diminuindo o valor da previsão, empurrando-a para a esquerda em direção ao valor mais baixo.\n",
    "\n",
    "- Comprimento da Seta: Indica a magnitude do impacto daquela feature. Setas mais longas significam uma contribuição mais forte.\n",
    "\n",
    "## Interpretação dos Resultados da Observação 0\n",
    "\n",
    "A previsão de r (0.2599) é significativamente inferior ao valor médio (0.4533).\n",
    "\n",
    "Isto implica que, para esta observação específica, o modelo identificou que as características predominantes (setas azuis) puxaram a previsão para baixo, resultando em uma estimativa de r bem abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## Observação\n",
    "\n",
    "- Um valor longe do valor médio, como mostrado no gráfico acima, não indica que o resultado foi ruim.\n",
    "\n",
    "- Podemos ver nas linhas de código abaixo que o valor `y_test_scaled`, que é o valor real normalizado, ficou próximo do valor normalizado previsto pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_y_teste_normalizado):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores normalizados de y contidos no caminho '{caminho_y_teste_normalizado}' não foram encontrados. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(y_test_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## 3.3 - Gráfico de Dependência (Dependence Plot - Relação Feature-Target)\n",
    "\n",
    "O gráfico abaixo ajuda a entender a forma (linear ou não linear) da relação entre uma feature e o target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # Explicando a relação da feature mais importante\n",
    "    most_important_feature = selected_feature_names[\n",
    "        0\n",
    "    ]  # Substitua pelo nome da sua feature principal\n",
    "\n",
    "    shap.dependence_plot(\n",
    "        most_important_feature,\n",
    "        shap_values_plot,\n",
    "        X_test_scaled,\n",
    "        interaction_index=None,  # Não mostra interação com outra feature\n",
    "        show=False,\n",
    "        feature_names=selected_feature_names,\n",
    "    )\n",
    "    plt.title(f\"Impacto do {most_important_feature} no Resultado\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.savefig(\n",
    "        f\"../data/08_reporting/shap_dependence_plot_{most_important_feature}_all_features.png\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## Explicação do gráfico acima\n",
    "\n",
    "- Eixo Y: Valor SHAP da Feature de interesse. Representa a contribuição real (o peso) que essa feature adiciona ou subtrai da previsão do modelo para aquela observação.\n",
    "- Eixo X: Valor Real da Feature de interesse. Mostra o valor escalado da variável.\n",
    "- Pontos: Cada ponto é uma observação individual do conjunto de teste.\n",
    "- Ausência de Cor: Com o interaction_index=None, os pontos não são coloridos por uma segunda feature. Eles refletem apenas a relação direta entre a feature de interesse e seu próprio impacto SHAP.\n",
    "\n",
    "## Como interpretar\n",
    "\n",
    "Ao analisar este gráfico, examina-se a forma da nuvem de pontos para entender a lógica do modelo.\n",
    "\n",
    "1. Relação Linear (Fácil de Interpretar)\n",
    "\n",
    "    Padrão: Os pontos formam uma linha reta ou tendem a seguir uma inclinação clara (seja positiva ou negativa).\n",
    "\n",
    "    Exemplo: Se, à medida que o valor da feature no Eixo X aumenta, o Valor SHAP no Eixo Y também aumenta (subindo da esquerda para a direita).\n",
    "\n",
    "    Conclusão: O modelo aprendeu uma relação linear simples: um aumento constante no valor da feature leva a um aumento constante na previsão.\n",
    "\n",
    "2. Relação Não Linear (Comum em Redes Neurais)\n",
    "\n",
    "    Padrão: Os pontos formam uma curva (ex: curva U, curva S invertida).\n",
    "\n",
    "    Exemplo: O Valor SHAP é baixo para valores extremos da feature (X baixo e X alto), mas o Valor SHAP se eleva significativamente para valores intermediários da feature.\n",
    "\n",
    "    Conclusão: O modelo aprendeu que o impacto da feature não é constante. Por exemplo, a variável é importante apenas dentro de um certo limite ótimo (o \"sweet spot\").\n",
    "\n",
    "3. Dispersão Vertical (Ruído e Interações Remotas)\n",
    "\n",
    "    Padrão: Em um valor específico no Eixo X (por exemplo, quando o valor da feature é 0.5), você vê os pontos dispersos verticalmente (ou seja, diferentes Valores SHAP).\n",
    "\n",
    "    Conclusão: Isso indica que, mesmo com o mesmo valor para a feature de interesse, seu impacto na previsão muda dependendo dos valores de outras features no modelo (as que você não está colorindo). O efeito é complexo e está sendo influenciado por interações de ordem superior que o modelo capturou.\n",
    "\n",
    "O Dependence Plot é uma ferramenta poderosa para validar se o modelo está aprendendo relações que fazem sentido no domínio do problema. Por exemplo, se uma relação linear é esperada e o gráfico mostra uma relação não linear, isso sugere que a Rede Neural descobriu uma dinâmica mais sutil nos dados. \n",
    "\n",
    "## Interpretação do gráfico gerado\n",
    "\n",
    "- O modelo aprendeu uma relação quase linear para essa feature, onde a contribuição marginal é mais significativa nas extremidades. Os Valores SHAP nulos na faixa intermediária da feature indicam que, nesse ponto, o efeito da feature sobre a previsão é neutro, ou seja, ele não contribui nem positivamente nem negativamente em relação à previsão média do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capacitacao-DnesvXxz-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
