{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42948c34",
   "metadata": {},
   "source": [
    "# Explicabilidade\n",
    "\n",
    "Os gráficos SHAP (SHapley Additive exPlanations) são uma boa forma de visualizar a importancia das features utilizadas e tirar insights de como as features estão ajudando o modelo a prever o target.\n",
    "\n",
    "Plota-se abaixo alguns gráficos SHAP para se obter mais insights sobre as features e seu impacto na predição do target.\n",
    "\n",
    "Para plotar os gráficos abaixo, precisa-se dos seguintes artefatos gerados nos notebooks anteriores:\n",
    "\n",
    "- shap_values\n",
    "    - caminho: '../data/08_reporting/<nome_do_arquivo>.npy'\n",
    "\n",
    "- X_test_scaled\n",
    "    - caminho: '../data/03_primary/<nome_do_arquivo>.npy'\n",
    "\n",
    "- selected_features\n",
    "    - caminho: '../data/08_reporting/<nome_do_arquivo>.npy'\n",
    "\n",
    "- modelo\n",
    "    -  caminho: '../data/06_models/<nome_do_arquivo>.joblib'\n",
    "\n",
    "- explainer\n",
    "    - caminho: '../data/08_reporting/<nome_do_arquivo>.pkl'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7725989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 20:02:28.669913: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-29 20:02:28.701822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-29 20:02:29.626566: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import joblib #Para salvar o modelo\n",
    "import pickle\n",
    "import os\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea79170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selecionadas\n",
    "\n",
    "caminho_features_selecionadas_all_features = '../data/08_reporting/selected_features_all_features.npy'\n",
    "\n",
    "caminho_features_selecionadas_non_linear_features = '../data/08_reporting/selected_non_linear_features.npy'\n",
    "\n",
    "caminho_features_selecionadas_linear_features = '../data/08_reporting/selected_linear_features.npy'\n",
    "\n",
    "# Caso os dvalores shapa já estejam calculados\n",
    "\n",
    "caminho_shap_all_features = '../data/08_reporting/shap_values_calculados_all_features.npy'\n",
    "\n",
    "caminho_shap_non_linear_features = '../data/08_reporting/shap_values_calculados.npy'\n",
    "\n",
    "caminho_shap_linear_features = '../data/08_reporting/shap_values_calculados_linear_features.npy'\n",
    "\n",
    "# Conjunto de treino normalizado para plotar o gráfico\n",
    "\n",
    "caminho_X_train_all_features = '../data/03_primary/X_train_all_features.npy'\n",
    "\n",
    "caminho_X_train_non_linear_features = '../data/03_primary/X_train_non_linear_features.npy'\n",
    "\n",
    "caminho_X_train_linear_features = '../data/03_primary/X_train_linear_features.npy'\n",
    "\n",
    "# Target de treino normalizado\n",
    "\n",
    "caminho_y_train_all_features = '../data/03_primary/y_train_all_features.npy'\n",
    "\n",
    "caminho_y_train_non_linear_features = '../data/03_primary/y_train_non_linear_features.npy'\n",
    "\n",
    "caminho_y_train_linear_features = '../data/03_primary/y_train_linear_features.npy'\n",
    "\n",
    "# Conjunto de teste normalizado para plotar o gráfico\n",
    "\n",
    "caminho_X_test_shap_all_features = '../data/03_primary/X_test_final_para_shap_all_features.npy'\n",
    "\n",
    "caminho_X_test_shap_non_linear_features = '../data/03_primary/X_test_final_para_shap.npy'\n",
    "\n",
    "caminho_X_test_shap_linear_features = '../data/03_primary/X_test_final_para_shap_linear_features.npy'\n",
    "\n",
    "# Target de teste normalizado\n",
    "\n",
    "#caminho_y_teste_shap_all_features = '../data/03_primary/y_test_final_para_shap_all_features.npy'\n",
    "\n",
    "#caminho_y_teste_shap_non_linear_features = '../data/03_primary/y_test_final_para_shap.npy'\n",
    "\n",
    "#caminho_y_teste_shap_linear_features = '../data/03_primary/y_test_final_para_shap_linear_features.npy'\n",
    "\n",
    "caminho_y_teste_normalizado = '../data/03_primary/y_teste_normalizado.npy'\n",
    "\n",
    "# shap explainers\n",
    "\n",
    "caminho_explainer_all_features = '../data/08_reporting/explainer_expected_value_all_features.pkl'\n",
    "\n",
    "caminho_explainer_non_linear_features = '../data/08_reporting/explainer_expected_value.pkl'\n",
    "\n",
    "caminho_explainer_linear_features = '../data/08_reporting/explainer_expected_value_linear_features.pkl'\n",
    "\n",
    "# modelos\n",
    "\n",
    "caminho_modelo_all_features = '../data/06_models/modelo_notebook_2_all_data.joblib'\n",
    "\n",
    "caminho_modelo_non_linear_features = '../data/06_models/modelo_notebook_3.joblib'\n",
    "\n",
    "caminho_modelo_linear_features = '../data/06_models/modelo_notebook_4.joblib'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658a1b2",
   "metadata": {},
   "source": [
    "# 1 - Modelo com todas as features\n",
    "\n",
    "Carregando ou calculando artefatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a80bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['l_2', 'l_3', 'l_4', 'l_5', 'l_6', 'l_7', 'l_8', 'l_9', 'l_10', 'l_11',\n",
      "       ...\n",
      "       'l_502', 'l_503', 'l_504', 'l_505', 'l_506', 'l_507', 'l_508', 'l_509',\n",
      "       'l_510', 'l_511'],\n",
      "      dtype='object', length=510)\n",
      "Valores SHAP e Expected Value não encontrados. Iniciando o cálculo demorado...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f24a77556d94504a87b9f773f324021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists(caminho_modelo_all_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: O modelo '{caminho_modelo_all_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # Carregamento dos dados necessários\n",
    "    X_test_scaled = np.load(caminho_X_test_shap_all_features, allow_pickle=True)\n",
    "    #y_test_scaled = np.load(caminho_y_teste_shap_all_features, allow_pickle=True)\n",
    "    y_test_scaled = np.load(caminho_y_teste_normalizado, allow_pickle=True)\n",
    "\n",
    "    # Carregamento dos nomes das features\n",
    "    with open(caminho_features_selecionadas_all_features, 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    selected_feature_names = loaded_data['list']\n",
    "\n",
    "    print(selected_feature_names)\n",
    "\n",
    "    # Carregamento do modelo (usando o caminho verificado)\n",
    "    best_nn_model = joblib.load(caminho_modelo_all_features)\n",
    "\n",
    "\n",
    "\n",
    "    # Verificação da existência dos SHAP Values e Expected Value (para evitar recálculo)\n",
    "    if os.path.exists(caminho_shap_all_features) and os.path.exists(caminho_explainer_all_features):\n",
    "        print(\"Valores SHAP e Expected Value já existem. Carregando...\")\n",
    "        \n",
    "        # Carregar os valores salvos \n",
    "        shap_values = np.load(caminho_shap_all_features, allow_pickle=True)\n",
    "\n",
    "        print(shap_values.shape)\n",
    "        \n",
    "        # Carrega o Expected Value \n",
    "        with open(caminho_explainer_all_features, 'rb') as f:\n",
    "            expected_value = pickle.load(f)\n",
    "            \n",
    "    else:\n",
    "        print(\"Valores SHAP e Expected Value não encontrados. Iniciando o cálculo demorado...\")\n",
    "        \n",
    "        X_train_scaled = np.load(caminho_X_train_all_features, allow_pickle=True)\n",
    "\n",
    "        # O KernelExplainer usa um \"background dataset\"\n",
    "        X_background = shap.sample(X_train_scaled, 100) \n",
    "\n",
    "    \n",
    "        # Cria o Explainer para calcular os valores\n",
    "        explainer = shap.KernelExplainer(\n",
    "            best_nn_model.predict, \n",
    "            X_background\n",
    "        )\n",
    "\n",
    "        # Calcula os Valores SHAP\n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "        expected_value = explainer.expected_value # Obtenha o valor base aqui\n",
    "\n",
    "        # SALVA OS VALORES (PARA EVITAR FUTUROS RECÁLCULOS) \n",
    "        np.save(caminho_shap_all_features, shap_values)\n",
    "\n",
    "        # Salva o Expected Value \n",
    "        with open(caminho_explainer_all_features, 'wb') as f:\n",
    "            pickle.dump(expected_value, f)\n",
    "\n",
    "        print(\"Cálculo concluído. Valores SHAP e Expected Value salvos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faea646",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_all_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_all_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    \n",
    "    if isinstance(shap_values, list):\n",
    "        # Pega o primeiro elemento da lista \n",
    "        shap_values_array = shap_values[0]\n",
    "\n",
    "    else:\n",
    "        shap_values_array = shap_values\n",
    "\n",
    "    # ACHATA o array de (2000, 510, 1) para (2000, 510)\n",
    "    shap_values_plot = np.squeeze(shap_values_array)\n",
    "\n",
    "    # Verificação após o squeeze \n",
    "    print(f\"Novo Shape de shap_values_plot: {shap_values_plot.shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2958c246",
   "metadata": {},
   "source": [
    "## 1.1 - Gráfico de Resumo Global (Summary Plot - Importância das Features)\n",
    "\n",
    "Este é o gráfico mais importante e mostra a importância global das features.\n",
    "\n",
    "    - Eixo Y: Features ordenadas por importância.\n",
    "\n",
    "    - Eixo X: Valor SHAP.\n",
    "\n",
    "    - Cor: Valor da feature (azul = baixo valor da feature, vermelho = alto valor da feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0efe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_shap_summary(\n",
    "    shap_values=shap_values,\n",
    "    shap_values_plot=shap_values_plot,\n",
    "    X_test_scaled=X_test_scaled,\n",
    "    selected_feature_names=selected_feature_names,\n",
    "    title=\"Modelo com todas as features: Importância Global das Features\",\n",
    "    save_filename='../data/08_reporting/shap_summary_plot_all_features.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22dda07",
   "metadata": {},
   "source": [
    "### Explicação do gráfico acima\n",
    "\n",
    "O Gráfico de Resumo SHAP é a maneira mais concisa de entender a importância e a direção do impacto de cada feature nas previsões.\n",
    "\n",
    "\n",
    "- Eixo Y: Lista as features (variáveis de entrada), ordenadas da mais importante (topo) para a menos importante (base), com base na magnitude média dos seus valores SHAP.\n",
    "\n",
    "- Eixo X: Representa o Valor SHAP. Este valor indica a contribuição (positiva ou negativa) de uma feature para a previsão do modelo em relação ao valor de previsão base (média).\n",
    "\n",
    "- Cor do Ponto: Representa o valor real da feature para aquela observação. Geralmente, Vermelho = Alto Valor da Feature (Alto na escala escalada) e Azul = Baixo Valor da Feature (Baixo na escala escalada).\n",
    "\n",
    "- Dispersão dos Pontos,Cada ponto é uma observação individual do conjunto de teste. A dispersão horizontal mostra o quão variável é o impacto dessa feature entre as observações. Quanto maior a dispersão de uma feature que já foi avaliada como importante, maior é a interação entre as features do modelo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Significado Visual do Gráfico\n",
    "\n",
    "- Linha de Base: O ponto central, geralmente rotulado como E[f(x)] (o Valor Base/Média, 0.5108), é o ponto de partida da previsão.\n",
    "\n",
    "- Setas Vermelhas (Forças Positivas): Representam as features que estão aumentando o valor da previsão, empurrando-a para a direita em direção ao valor mais alto.\n",
    "\n",
    "- Setas Azuis (Forças Negativas): Representam as features que estão diminuindo o valor da previsão, empurrando-a para a esquerda em direção ao valor mais baixo.\n",
    "\n",
    "- Comprimento da Seta: Indica a magnitude do impacto daquela feature. Setas mais longas significam uma contribuição mais forte.\n",
    "\n",
    "### Interpretação dos Resultados da Observação 0\n",
    "\n",
    "A previsão de r (0.2748) é significativamente inferior ao valor médio (0.5108).\n",
    "\n",
    "Isto implica que, para esta observação específica, o modelo identificou que as características predominantes (setas azuis) puxaram a previsão para baixo, resultando em uma estimativa de r bem abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7448611f",
   "metadata": {},
   "source": [
    "## 1.2 - Gráfico de Força (Force Plot - Explicação Local)\n",
    "\n",
    "O gráfico abaixo explica uma única previsão. Ele mostra como cada feature empurra a previsão da linha de base (valor médio) para o valor final previsto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e09b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_all_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_all_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    observation_index = 0\n",
    "\n",
    "    utils.generate_shap_force_plot(\n",
    "        model = best_nn_model,\n",
    "        explainer_expected_value = expected_value,\n",
    "        shap_values_plot = shap_values_plot,\n",
    "        X_test_scaled = X_test_scaled,\n",
    "        selected_feature_names= selected_feature_names,\n",
    "        observation_index = observation_index,\n",
    "        save_filename_prefix = '../data/08_reporting/shap_force_plot_all_features',\n",
    "        dpi = 300\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271a009",
   "metadata": {},
   "source": [
    "## Explicação do gráfico acima\n",
    "\n",
    "O Force Plot (Gráfico de Força) fornece uma explicação local, detalhando exatamente como cada feature da Observação 0 contribuiu para a previsão final do modelo.\n",
    "\n",
    "A observação 0 é a primeira linha do dataset.\n",
    "\n",
    "- Valor Base (Média): 0.4533,\n",
    "    - Significado: É a previsão média de r (ou a média dos targets escalados) para todo o conjunto de dados. Representa o ponto de partida do modelo antes de considerar as features específicas da observação.\n",
    "- Valor Previsto: 0.2599\n",
    "    - Significado: É o valor final previsto para r pelo modelo, após considerar todas as features específicas da Observação 0.\"\n",
    "\n",
    "## Significado Visual do Gráfico\n",
    "\n",
    "- Linha de Base: O ponto central, geralmente rotulado como E[f(x)] (o Valor Base/Média, 0.5108), é o ponto de partida da previsão.\n",
    "\n",
    "- Setas Vermelhas (Forças Positivas): Representam as features que estão aumentando o valor da previsão, empurrando-a para a direita em direção ao valor mais alto.\n",
    "\n",
    "- Setas Azuis (Forças Negativas): Representam as features que estão diminuindo o valor da previsão, empurrando-a para a esquerda em direção ao valor mais baixo.\n",
    "\n",
    "- Comprimento da Seta: Indica a magnitude do impacto daquela feature. Setas mais longas significam uma contribuição mais forte.\n",
    "\n",
    "## Interpretação dos Resultados da Observação 0\n",
    "\n",
    "A previsão de r (0.2599) é significativamente inferior ao valor médio (0.4533).\n",
    "\n",
    "Isto implica que, para esta observação específica, o modelo identificou que as características predominantes (setas azuis) puxaram a previsão para baixo, resultando em uma estimativa de r bem abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b4818",
   "metadata": {},
   "source": [
    "## Observação\n",
    "\n",
    "- Um valor longe do valor médio, como mostrado no gráfico acima, não indica que o resultado foi ruim.\n",
    "\n",
    "- Podemos ver nas linhas de código abaixo que o valor `y_test_scaled`, que é o valor real normalizado, ficou próximo do valor normalizado previsto pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_y_teste_normalizado):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores normalizados de y contidos no caminho '{caminho_y_teste_normalizado}' não foram encontrados. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(y_test_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6281185b",
   "metadata": {},
   "source": [
    "## 1.3 - Gráfico de Dependência (Dependence Plot - Relação Feature-Target)\n",
    "\n",
    "O gráfico abaixo ajuda a entender a forma (linear ou não linear) da relação entre uma feature e o target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87038bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_all_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_all_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Explicando a relação da feature mais importante \n",
    "    most_important_feature = 'l_120' # Substitua pelo nome da sua feature principal\n",
    "\n",
    "    shap.dependence_plot(\n",
    "        most_important_feature, \n",
    "        shap_values_plot, \n",
    "        X_test_scaled, \n",
    "        interaction_index=None, # Não mostra interação com outra feature\n",
    "        show=False,\n",
    "        feature_names=selected_feature_names\n",
    "    )\n",
    "    plt.title(f\"Impacto do {most_important_feature} no Resultado\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.savefig(\n",
    "        f'../data/08_reporting/shap_dependence_plot_{most_important_feature}_all_features.png', \n",
    "        dpi=300, \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f97ea",
   "metadata": {},
   "source": [
    "## Explicação do gráfico acima\n",
    "\n",
    "- Eixo Y: Valor SHAP da Feature de interesse. Representa a contribuição real (o peso) que essa feature adiciona ou subtrai da previsão do modelo para aquela observação.\n",
    "- Eixo X: Valor Real da Feature de interesse. Mostra o valor escalado da variável.\n",
    "- Pontos: Cada ponto é uma observação individual do conjunto de teste.\n",
    "- Ausência de Cor: Com o interaction_index=None, os pontos não são coloridos por uma segunda feature. Eles refletem apenas a relação direta entre a feature de interesse e seu próprio impacto SHAP.\n",
    "\n",
    "## Como interpretar\n",
    "\n",
    "Ao analisar este gráfico, examina-se a forma da nuvem de pontos para entender a lógica do modelo.\n",
    "\n",
    "1. Relação Linear (Fácil de Interpretar)\n",
    "\n",
    "    Padrão: Os pontos formam uma linha reta ou tendem a seguir uma inclinação clara (seja positiva ou negativa).\n",
    "\n",
    "    Exemplo: Se, à medida que o valor da feature no Eixo X aumenta, o Valor SHAP no Eixo Y também aumenta (subindo da esquerda para a direita).\n",
    "\n",
    "    Conclusão: O modelo aprendeu uma relação linear simples: um aumento constante no valor da feature leva a um aumento constante na previsão.\n",
    "\n",
    "2. Relação Não Linear (Comum em Redes Neurais)\n",
    "\n",
    "    Padrão: Os pontos formam uma curva (ex: curva U, curva S invertida).\n",
    "\n",
    "    Exemplo: O Valor SHAP é baixo para valores extremos da feature (X baixo e X alto), mas o Valor SHAP se eleva significativamente para valores intermediários da feature.\n",
    "\n",
    "    Conclusão: O modelo aprendeu que o impacto da feature não é constante. Por exemplo, a variável é importante apenas dentro de um certo limite ótimo (o \"sweet spot\").\n",
    "\n",
    "3. Dispersão Vertical (Ruído e Interações Remotas)\n",
    "\n",
    "    Padrão: Em um valor específico no Eixo X (por exemplo, quando o valor da feature é 0.5), você vê os pontos dispersos verticalmente (ou seja, diferentes Valores SHAP).\n",
    "\n",
    "    Conclusão: Isso indica que, mesmo com o mesmo valor para a feature de interesse, seu impacto na previsão muda dependendo dos valores de outras features no modelo (as que você não está colorindo). O efeito é complexo e está sendo influenciado por interações de ordem superior que o modelo capturou.\n",
    "\n",
    "O Dependence Plot é uma ferramenta poderosa para validar se o modelo está aprendendo relações que fazem sentido no domínio do problema. Por exemplo, se uma relação linear é esperada e o gráfico mostra uma relação não linear, isso sugere que a Rede Neural descobriu uma dinâmica mais sutil nos dados. \n",
    "\n",
    "## Interpretação do gráfico gerado\n",
    "\n",
    "- O modelo aprendeu uma relação quase linear para essa feature, onde a contribuição marginal é mais significativa nas extremidades. Os Valores SHAP nulos na faixa intermediária da feature indicam que, nesse ponto, o efeito da feature sobre a previsão é neutro, ou seja, ele não contribui nem positivamente nem negativamente em relação à previsão média do modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d42df5",
   "metadata": {},
   "source": [
    "# 2 - Modelo com seleção de features não linear\n",
    "\n",
    "Carregando ou calculando artefatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e758ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_modelo_non_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: O modelo '{caminho_modelo_non_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # Carregamento dos dados necessários\n",
    "    X_test_scaled = np.load(caminho_X_test_shap_non_linear_features, allow_pickle=True)\n",
    "    y_test_scaled = np.load(caminho_y_teste_normalizado, allow_pickle=True)\n",
    "\n",
    "    # Carregamento dos nomes das features\n",
    "    with open(caminho_features_selecionadas_non_linear_features, 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    selected_feature_names = loaded_data['list']\n",
    "\n",
    "    print(selected_feature_names.shape)\n",
    "\n",
    "    # Carregamento do modelo \n",
    "    best_nn_model = joblib.load(caminho_modelo_non_linear_features)\n",
    "\n",
    "\n",
    "\n",
    "    # Verificação da existência dos SHAP Values e Expected Value (para evitar recálculo)\n",
    "    if os.path.exists(caminho_shap_non_linear_features) and os.path.exists(caminho_explainer_non_linear_features):\n",
    "        print(\"Valores SHAP e Expected Value já existem. Carregando...\")\n",
    "        \n",
    "        # Carregar os valores salvos\n",
    "        shap_values = np.load(caminho_shap_non_linear_features, allow_pickle=True)\n",
    "        \n",
    "        # Carregar o Expected Value\n",
    "        with open(caminho_explainer_non_linear_features, 'rb') as f:\n",
    "            expected_value = pickle.load(f)\n",
    "            \n",
    "    else:\n",
    "        print(\"Valores SHAP e Expected Value não encontrados. Iniciando o cálculo demorado...\")\n",
    "        \n",
    "        X_train_scaled = np.load(caminho_X_train_non_linear_features, allow_pickle=True)\n",
    "\n",
    "        # O KernelExplainer usa um \"background dataset\"\n",
    "        X_background = shap.sample(X_train_scaled, 100) \n",
    "\n",
    "        # Cria o Explainer para calcular os valores\n",
    "        explainer = shap.KernelExplainer(\n",
    "            best_nn_model.predict, \n",
    "            X_background\n",
    "        )\n",
    "\n",
    "        # Calcula os Valores SHAP\n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "        expected_value = explainer.expected_value # Obtenha o valor base aqui\n",
    "\n",
    "        # SALVA OS VALORES (PARA EVITAR FUTUROS RECÁLCULOS) \n",
    "        np.save(caminho_shap_non_linear_features, shap_values)\n",
    "\n",
    "        # Salvar o Expected Value \n",
    "        with open(caminho_explainer_non_linear_features, 'wb') as f:\n",
    "            pickle.dump(expected_value, f)\n",
    "\n",
    "        print(\"Cálculo concluído. Valores SHAP e Expected Value salvos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a468e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_non_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_non_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    \n",
    "    if isinstance(shap_values, list):\n",
    "        # Pega o primeiro elemento da lista \n",
    "        shap_values_array = shap_values[0]\n",
    "\n",
    "    else:\n",
    "        shap_values_array = shap_values\n",
    "\n",
    "    # ACHATA o array de (2000, 510, 1) para (2000, 510)\n",
    "    shap_values_plot = np.squeeze(shap_values_array)\n",
    "\n",
    "    # Verificação após o squeeze \n",
    "    print(f\"Novo Shape de shap_values_plot: {shap_values_plot.shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf7a93",
   "metadata": {},
   "source": [
    "## 2.1 - Gráfico de Resumo Global (Summary Plot - Importância das Features)\n",
    "\n",
    "Este é o gráfico mais importante e mostra a importância global das features.\n",
    "\n",
    "    - Eixo Y: Features ordenadas por importância.\n",
    "\n",
    "    - Eixo X: Valor SHAP.\n",
    "\n",
    "    - Cor: Valor da feature (azul = baixo valor da feature, vermelho = alto valor da feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed86d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_shap_summary(\n",
    "    shap_values=shap_values,\n",
    "    shap_values_plot=shap_values_plot,\n",
    "    X_test_scaled=X_test_scaled,\n",
    "    selected_feature_names=selected_feature_names,\n",
    "    title=\"Modelo com seleção linear de features: Importância Global das Features\",\n",
    "    save_filename='../data/08_reporting/shap_summary_plot_non_linear_features.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde980e",
   "metadata": {},
   "source": [
    "### Explicação do gráfico acima\n",
    "\n",
    "O Gráfico de Resumo SHAP é a maneira mais concisa de entender a importância e a direção do impacto de cada feature nas previsões.\n",
    "\n",
    "\n",
    "- Eixo Y: Lista as features (variáveis de entrada), ordenadas da mais importante (topo) para a menos importante (base), com base na magnitude média dos seus valores SHAP.\n",
    "\n",
    "- Eixo X: Representa o Valor SHAP. Este valor indica a contribuição (positiva ou negativa) de uma feature para a previsão do modelo em relação ao valor de previsão base (média).\n",
    "\n",
    "- Cor do Ponto: Representa o valor real da feature para aquela observação. Geralmente, Vermelho = Alto Valor da Feature (Alto na escala escalada) e Azul = Baixo Valor da Feature (Baixo na escala escalada).\n",
    "\n",
    "- Dispersão dos Pontos,Cada ponto é uma observação individual do conjunto de teste. A dispersão horizontal mostra o quão variável é o impacto dessa feature entre as observações. Quanto maior a dispersão de uma feature que já foi avaliada como importante, maior é a interação entre as features do modelo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Significado Visual do Gráfico\n",
    "\n",
    "- Linha de Base: O ponto central, geralmente rotulado como E[f(x)] (o Valor Base/Média, 0.5108), é o ponto de partida da previsão.\n",
    "\n",
    "- Setas Vermelhas (Forças Positivas): Representam as features que estão aumentando o valor da previsão, empurrando-a para a direita em direção ao valor mais alto.\n",
    "\n",
    "- Setas Azuis (Forças Negativas): Representam as features que estão diminuindo o valor da previsão, empurrando-a para a esquerda em direção ao valor mais baixo.\n",
    "\n",
    "- Comprimento da Seta: Indica a magnitude do impacto daquela feature. Setas mais longas significam uma contribuição mais forte.\n",
    "\n",
    "### Interpretação dos Resultados da Observação 0\n",
    "\n",
    "A previsão de r (0.2748) é significativamente inferior ao valor médio (0.5108).\n",
    "\n",
    "Isto implica que, para esta observação específica, o modelo identificou que as características predominantes (setas azuis) puxaram a previsão para baixo, resultando em uma estimativa de r bem abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d2a18",
   "metadata": {},
   "source": [
    "## 2.2 - Gráfico de Força (Force Plot - Explicação Local)\n",
    "\n",
    "O gráfico abaixo explica uma única previsão. Ele mostra como cada feature empurra a previsão da linha de base (valor médio) para o valor final previsto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae49f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_non_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_non_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    observation_index = 0\n",
    "\n",
    "    utils.generate_shap_force_plot(\n",
    "        model = best_nn_model,\n",
    "        explainer_expected_value = expected_value,\n",
    "        shap_values_plot = shap_values_plot,\n",
    "        X_test_scaled = X_test_scaled,\n",
    "        selected_feature_names= selected_feature_names,\n",
    "        observation_index = observation_index,\n",
    "        save_filename_prefix = '../data/08_reporting/shap_force_plot_non_linear_features',\n",
    "        dpi = 300\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f74f83",
   "metadata": {},
   "source": [
    "## Explicação do gráfico acima\n",
    "\n",
    "O Force Plot (Gráfico de Força) fornece uma explicação local, detalhando exatamente como cada feature da Observação 0 contribuiu para a previsão final do modelo.\n",
    "\n",
    "A observação 0 é a primeira linha do dataset.\n",
    "\n",
    "- Valor Base (Média): 0.4457,\n",
    "    - Significado: É a previsão média de r (ou a média dos targets escalados) para todo o conjunto de dados. Representa o ponto de partida do modelo antes de considerar as features específicas da observação.\n",
    "- Valor Previsto: 0.2794\n",
    "    - Significado: É o valor final previsto para r pelo modelo, após considerar todas as features específicas da Observação 0.\"\n",
    "\n",
    "## Significado Visual do Gráfico\n",
    "\n",
    "- Linha de Base: O ponto central, geralmente rotulado como E[f(x)] (o Valor Base/Média, 0.4457), é o ponto de partida da previsão.\n",
    "\n",
    "- Setas Vermelhas (Forças Positivas): Representam as features que estão aumentando o valor da previsão, empurrando-a para a direita em direção ao valor mais alto.\n",
    "\n",
    "- Setas Azuis (Forças Negativas): Representam as features que estão diminuindo o valor da previsão, empurrando-a para a esquerda em direção ao valor mais baixo.\n",
    "\n",
    "- Comprimento da Seta: Indica a magnitude do impacto daquela feature. Setas mais longas significam uma contribuição mais forte.\n",
    "\n",
    "## Interpretação dos Resultados da Observação 0\n",
    "\n",
    "A previsão de r (0.2794) é significativamente inferior ao valor médio (0.4457).\n",
    "\n",
    "Isto implica que, para esta observação específica, o modelo identificou que as características predominantes (setas azuis) puxaram a previsão para baixo, resultando em uma estimativa de r bem abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df238bfc",
   "metadata": {},
   "source": [
    "## Observação\n",
    "\n",
    "- Um valor longe do valor médio, como mostrado no gráfico acima, não indica que o resultado foi ruim.\n",
    "\n",
    "- Podemos ver nas linhas de código abaixo que o valor `y_test_scaled`, que é o valor real normalizado, ficou próximo do valor normalizado previsto pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4febd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_y_teste_normalizado):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores normalizados de y contidos no caminho '{caminho_y_teste_normalizado}' não foram encontrados. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(y_test_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935b814",
   "metadata": {},
   "source": [
    "## 2.3 - Gráfico de Dependência (Dependence Plot - Relação Feature-Target)\n",
    "\n",
    "O Gráfico de Dependência SHAP (SHAP Dependence Plot) é projetado para mostrar como a relação entre uma feature específica e o resultado do modelo se parece. Em essência, é uma versão explicável do tradicional gráfico de dispersão, ajudando a visualizar a forma (linear, não linear, ou complexa) que o modelo aprendeu para essa variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1590b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc41d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_non_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_non_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Explicando a relação da feature mais importante \n",
    "    most_important_feature = selected_feature_names[0] # Substitua pelo nome da sua feature principal\n",
    "\n",
    "    shap.dependence_plot(\n",
    "        most_important_feature, \n",
    "        shap_values_plot, \n",
    "        X_test_scaled, \n",
    "        interaction_index=None, # Não mostra interação com outra feature\n",
    "        show=False,\n",
    "        feature_names=selected_feature_names\n",
    "    )\n",
    "    plt.title(f\"Impacto do {most_important_feature} no Resultado\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.savefig(\n",
    "        f'../data/08_reporting/shap_dependence_plot_{most_important_feature}_non_linear_features.png', \n",
    "        dpi=300, \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7528a7",
   "metadata": {},
   "source": [
    "## Explicação do gráfico acima\n",
    "\n",
    "- Eixo Y: Valor SHAP da Feature de interesse. Representa a contribuição real (o peso) que essa feature adiciona ou subtrai da previsão do modelo para aquela observação.\n",
    "- Eixo X: Valor Real da Feature de interesse. Mostra o valor escalado da variável.\n",
    "- Pontos: Cada ponto é uma observação individual do conjunto de teste.\n",
    "- Ausência de Cor: Com o interaction_index=None, os pontos não são coloridos por uma segunda feature. Eles refletem apenas a relação direta entre a feature de interesse e seu próprio impacto SHAP.\n",
    "\n",
    "## Como interpretar\n",
    "\n",
    "Ao analisar este gráfico, examina-se a forma da nuvem de pontos para entender a lógica do modelo.\n",
    "\n",
    "1. Relação Linear (Fácil de Interpretar)\n",
    "\n",
    "    Padrão: Os pontos formam uma linha reta ou tendem a seguir uma inclinação clara (seja positiva ou negativa).\n",
    "\n",
    "    Exemplo: Se, à medida que o valor da feature no Eixo X aumenta, o Valor SHAP no Eixo Y também aumenta (subindo da esquerda para a direita).\n",
    "\n",
    "    Conclusão: O modelo aprendeu uma relação linear simples: um aumento constante no valor da feature leva a um aumento constante na previsão.\n",
    "\n",
    "2. Relação Não Linear (Comum em Redes Neurais)\n",
    "\n",
    "    Padrão: Os pontos formam uma curva (ex: curva U, curva S invertida).\n",
    "\n",
    "    Exemplo: O Valor SHAP é baixo para valores extremos da feature (X baixo e X alto), mas o Valor SHAP se eleva significativamente para valores intermediários da feature.\n",
    "\n",
    "    Conclusão: O modelo aprendeu que o impacto da feature não é constante. Por exemplo, a variável é importante apenas dentro de um certo limite ótimo (o \"sweet spot\").\n",
    "\n",
    "3. Dispersão Vertical (Ruído e Interações Remotas)\n",
    "\n",
    "    Padrão: Em um valor específico no Eixo X (por exemplo, quando o valor da feature é 0.5), você vê os pontos dispersos verticalmente (ou seja, diferentes Valores SHAP).\n",
    "\n",
    "    Conclusão: Isso indica que, mesmo com o mesmo valor para a feature de interesse, seu impacto na previsão muda dependendo dos valores de outras features no modelo (as que você não está colorindo). O efeito é complexo e está sendo influenciado por interações de ordem superior que o modelo capturou.\n",
    "\n",
    "O Dependence Plot é uma ferramenta poderosa para validar se o modelo está aprendendo relações que fazem sentido no domínio do problema. Por exemplo, se uma relação linear é esperada e o gráfico mostra uma relação não linear, isso sugere que a Rede Neural descobriu uma dinâmica mais sutil nos dados. \n",
    "\n",
    "## Interpretação do gráfico gerado\n",
    "\n",
    "- O modelo aprendeu uma relação quase linear para essa feature, onde a contribuição marginal é mais significativa nas extremidades. Os Valores SHAP nulos na faixa intermediária da feature indicam que, nesse ponto, o efeito da feature sobre a previsão é neutro, ou seja, ele não contribui nem positivamente nem negativamente em relação à previsão média do modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8deb3",
   "metadata": {},
   "source": [
    "# 3 - Modelo com seleção de features linear\n",
    "\n",
    "Carregando ou calculando artefatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_modelo_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: O modelo '{caminho_modelo_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # Carregamento dos dados necessários\n",
    "    X_test_scaled = np.load(caminho_X_test_shap_linear_features, allow_pickle=True)\n",
    "    y_test_scaled = np.load(caminho_y_teste_normalizado, allow_pickle=True)\n",
    "\n",
    "    # Carregamento dos nomes das features\n",
    "    with open(caminho_features_selecionadas_linear_features, 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    selected_feature_names = loaded_data['list']\n",
    "\n",
    "    print(selected_feature_names.shape)\n",
    "\n",
    "    # Carregamento do modelo (usando o caminho verificado)\n",
    "    best_nn_model = joblib.load(caminho_modelo_linear_features)\n",
    "\n",
    "\n",
    "\n",
    "    # Verificação da existência dos SHAP Values e Expected Value (para evitar recálculo)\n",
    "    if os.path.exists(caminho_shap_linear_features) and os.path.exists(caminho_explainer_linear_features):\n",
    "        print(\"Valores SHAP e Expected Value já existem. Carregando...\")\n",
    "        \n",
    "        # Carregar os valores salvos\n",
    "        shap_values = np.load(caminho_shap_linear_features, allow_pickle=True)\n",
    "        \n",
    "        # Carregar o Expected Value (que você salvou)\n",
    "        with open(caminho_explainer_linear_features, 'rb') as f:\n",
    "            expected_value = pickle.load(f)\n",
    "            \n",
    "    else:\n",
    "        print(\"Valores SHAP e Expected Value não encontrados. Iniciando o cálculo demorado...\")\n",
    "        \n",
    "        X_train_scaled = np.load(caminho_X_train_linear_features, allow_pickle=True)\n",
    "\n",
    "        # O KernelExplainer usa um \"background dataset\"\n",
    "        X_background = shap.sample(X_train_scaled, 100) \n",
    "\n",
    "        # Cria o Explainer para calcular os valores\n",
    "        explainer = shap.KernelExplainer(\n",
    "            best_nn_model.predict, \n",
    "            X_background\n",
    "        )\n",
    "\n",
    "        # Calcular os Valores SHAP \n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "        expected_value = explainer.expected_value # Obtenha o valor base aqui\n",
    "\n",
    "        # SALVA OS VALORES (PARA EVITAR FUTUROS RECÁLCULOS) \n",
    "        np.save(caminho_shap_linear_features, shap_values)\n",
    "\n",
    "        # Salvar o Expected Value\n",
    "        with open(caminho_explainer_linear_features, 'wb') as f:\n",
    "            pickle.dump(expected_value, f)\n",
    "\n",
    "        print(\"Cálculo concluído. Valores SHAP e Expected Value salvos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cee75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e946391",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    \n",
    "    if isinstance(shap_values, list):\n",
    "        # Pega o primeiro elemento da lista \n",
    "        shap_values_array = shap_values[0]\n",
    "\n",
    "    else:\n",
    "        shap_values_array = shap_values\n",
    "\n",
    "    # ACHATA o array de (2000, 510, 1) para (2000, 510)\n",
    "    shap_values_plot = np.squeeze(shap_values_array)\n",
    "\n",
    "    # Verificação após o squeeze \n",
    "    print(f\"Novo Shape de shap_values_plot: {shap_values_plot.shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a476013a",
   "metadata": {},
   "source": [
    "## 3.1 - Gráfico de Resumo Global (Summary Plot - Importância das Features)\n",
    "\n",
    "Este é o gráfico mais importante e mostra a importância global das features.\n",
    "\n",
    "    - Eixo Y: Features ordenadas por importância.\n",
    "\n",
    "    - Eixo X: Valor SHAP.\n",
    "\n",
    "    - Cor: Valor da feature (azul = baixo valor da feature, vermelho = alto valor da feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_shap_summary(\n",
    "    shap_values=shap_values,\n",
    "    shap_values_plot=shap_values_plot,\n",
    "    X_test_scaled=X_test_scaled,\n",
    "    selected_feature_names=selected_feature_names,\n",
    "    title=\"Modelo com seleção linear de features: Importância Global das Features\",\n",
    "    save_filename='../data/08_reporting/shap_summary_plot_linear_features.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53039951",
   "metadata": {},
   "source": [
    "### Explicação do gráfico acima\n",
    "\n",
    "O Gráfico de Resumo SHAP é a maneira mais concisa de entender a importância e a direção do impacto de cada feature nas previsões.\n",
    "\n",
    "\n",
    "- Eixo Y: Lista as features (variáveis de entrada), ordenadas da mais importante (topo) para a menos importante (base), com base na magnitude média dos seus valores SHAP.\n",
    "\n",
    "- Eixo X: Representa o Valor SHAP. Este valor indica a contribuição (positiva ou negativa) de uma feature para a previsão do modelo em relação ao valor de previsão base (média).\n",
    "\n",
    "- Cor do Ponto: Representa o valor real da feature para aquela observação. Geralmente, Vermelho = Alto Valor da Feature (Alto na escala escalada) e Azul = Baixo Valor da Feature (Baixo na escala escalada).\n",
    "\n",
    "- Dispersão dos Pontos,Cada ponto é uma observação individual do conjunto de teste. A dispersão horizontal mostra o quão variável é o impacto dessa feature entre as observações. Quanto maior a dispersão de uma feature que já foi avaliada como importante, maior é a interação entre as features do modelo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Significado Visual do Gráfico\n",
    "\n",
    "- Linha de Base: O ponto central, geralmente rotulado como E[f(x)] (o Valor Base/Média, 0.5108), é o ponto de partida da previsão.\n",
    "\n",
    "- Setas Vermelhas (Forças Positivas): Representam as features que estão aumentando o valor da previsão, empurrando-a para a direita em direção ao valor mais alto.\n",
    "\n",
    "- Setas Azuis (Forças Negativas): Representam as features que estão diminuindo o valor da previsão, empurrando-a para a esquerda em direção ao valor mais baixo.\n",
    "\n",
    "- Comprimento da Seta: Indica a magnitude do impacto daquela feature. Setas mais longas significam uma contribuição mais forte.\n",
    "\n",
    "### Interpretação dos Resultados da Observação 0\n",
    "\n",
    "A previsão de r (0.2748) é significativamente inferior ao valor médio (0.5108).\n",
    "\n",
    "Isto implica que, para esta observação específica, o modelo identificou que as características predominantes (setas azuis) puxaram a previsão para baixo, resultando em uma estimativa de r bem abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff6f54",
   "metadata": {},
   "source": [
    "## 3.2 - Gráfico de Força (Force Plot - Explicação Local)\n",
    "\n",
    "O gráfico abaixo explica uma única previsão. Ele mostra como cada feature empurra a previsão da linha de base (valor médio) para o valor final previsto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3455825",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    observation_index = 0\n",
    "\n",
    "    utils.generate_shap_force_plot(\n",
    "        model = best_nn_model,\n",
    "        explainer_expected_value = expected_value,\n",
    "        shap_values_plot = shap_values_plot,\n",
    "        X_test_scaled = X_test_scaled,\n",
    "        selected_feature_names= selected_feature_names,\n",
    "        observation_index = observation_index,\n",
    "        save_filename_prefix = '../data/08_reporting/shap_force_plot_linear_features',\n",
    "        dpi = 300\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b98a7f",
   "metadata": {},
   "source": [
    "## Explicação do gráfico acima\n",
    "\n",
    "O Force Plot (Gráfico de Força) fornece uma explicação local, detalhando exatamente como cada feature da Observação 0 contribuiu para a previsão final do modelo.\n",
    "\n",
    "A observação 0 é a primeira linha do dataset.\n",
    "\n",
    "- Valor Base (Média): 0.4533,\n",
    "    - Significado: É a previsão média de r (ou a média dos targets escalados) para todo o conjunto de dados. Representa o ponto de partida do modelo antes de considerar as features específicas da observação.\n",
    "- Valor Previsto: 0.2599\n",
    "    - Significado: É o valor final previsto para r pelo modelo, após considerar todas as features específicas da Observação 0.\"\n",
    "\n",
    "## Significado Visual do Gráfico\n",
    "\n",
    "- Linha de Base: O ponto central, geralmente rotulado como E[f(x)] (o Valor Base/Média, 0.5108), é o ponto de partida da previsão.\n",
    "\n",
    "- Setas Vermelhas (Forças Positivas): Representam as features que estão aumentando o valor da previsão, empurrando-a para a direita em direção ao valor mais alto.\n",
    "\n",
    "- Setas Azuis (Forças Negativas): Representam as features que estão diminuindo o valor da previsão, empurrando-a para a esquerda em direção ao valor mais baixo.\n",
    "\n",
    "- Comprimento da Seta: Indica a magnitude do impacto daquela feature. Setas mais longas significam uma contribuição mais forte.\n",
    "\n",
    "## Interpretação dos Resultados da Observação 0\n",
    "\n",
    "A previsão de r (0.2599) é significativamente inferior ao valor médio (0.4533).\n",
    "\n",
    "Isto implica que, para esta observação específica, o modelo identificou que as características predominantes (setas azuis) puxaram a previsão para baixo, resultando em uma estimativa de r bem abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae4f493",
   "metadata": {},
   "source": [
    "## Observação\n",
    "\n",
    "- Um valor longe do valor médio, como mostrado no gráfico acima, não indica que o resultado foi ruim.\n",
    "\n",
    "- Podemos ver nas linhas de código abaixo que o valor `y_test_scaled`, que é o valor real normalizado, ficou próximo do valor normalizado previsto pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb95470",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_y_teste_normalizado):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores normalizados de y contidos no caminho '{caminho_y_teste_normalizado}' não foram encontrados. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(y_test_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d55c9",
   "metadata": {},
   "source": [
    "## 3.3 - Gráfico de Dependência (Dependence Plot - Relação Feature-Target)\n",
    "\n",
    "O gráfico abaixo ajuda a entender a forma (linear ou não linear) da relação entre uma feature e o target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de318c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(caminho_shap_linear_features):\n",
    "    # Lança um erro se o arquivo não for encontrado\n",
    "    raise FileNotFoundError(\n",
    "        f\"ERRO: Os valores shap contidos em '{caminho_shap_linear_features}' não foi encontrado. \"\n",
    "        \"Execute o notebook/script de treinamento do modelo primeiro.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Explicando a relação da feature mais importante \n",
    "    most_important_feature = selected_feature_names[0] # Substitua pelo nome da sua feature principal\n",
    "\n",
    "    shap.dependence_plot(\n",
    "        most_important_feature, \n",
    "        shap_values_plot, \n",
    "        X_test_scaled, \n",
    "        interaction_index=None, # Não mostra interação com outra feature\n",
    "        show=False,\n",
    "        feature_names=selected_feature_names\n",
    "    )\n",
    "    plt.title(f\"Impacto do {most_important_feature} no Resultado\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.savefig(\n",
    "        f'../data/08_reporting/shap_dependence_plot_{most_important_feature}_all_features.png', \n",
    "        dpi=300, \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c16380",
   "metadata": {},
   "source": [
    "## Explicação do gráfico acima\n",
    "\n",
    "- Eixo Y: Valor SHAP da Feature de interesse. Representa a contribuição real (o peso) que essa feature adiciona ou subtrai da previsão do modelo para aquela observação.\n",
    "- Eixo X: Valor Real da Feature de interesse. Mostra o valor escalado da variável.\n",
    "- Pontos: Cada ponto é uma observação individual do conjunto de teste.\n",
    "- Ausência de Cor: Com o interaction_index=None, os pontos não são coloridos por uma segunda feature. Eles refletem apenas a relação direta entre a feature de interesse e seu próprio impacto SHAP.\n",
    "\n",
    "## Como interpretar\n",
    "\n",
    "Ao analisar este gráfico, examina-se a forma da nuvem de pontos para entender a lógica do modelo.\n",
    "\n",
    "1. Relação Linear (Fácil de Interpretar)\n",
    "\n",
    "    Padrão: Os pontos formam uma linha reta ou tendem a seguir uma inclinação clara (seja positiva ou negativa).\n",
    "\n",
    "    Exemplo: Se, à medida que o valor da feature no Eixo X aumenta, o Valor SHAP no Eixo Y também aumenta (subindo da esquerda para a direita).\n",
    "\n",
    "    Conclusão: O modelo aprendeu uma relação linear simples: um aumento constante no valor da feature leva a um aumento constante na previsão.\n",
    "\n",
    "2. Relação Não Linear (Comum em Redes Neurais)\n",
    "\n",
    "    Padrão: Os pontos formam uma curva (ex: curva U, curva S invertida).\n",
    "\n",
    "    Exemplo: O Valor SHAP é baixo para valores extremos da feature (X baixo e X alto), mas o Valor SHAP se eleva significativamente para valores intermediários da feature.\n",
    "\n",
    "    Conclusão: O modelo aprendeu que o impacto da feature não é constante. Por exemplo, a variável é importante apenas dentro de um certo limite ótimo (o \"sweet spot\").\n",
    "\n",
    "3. Dispersão Vertical (Ruído e Interações Remotas)\n",
    "\n",
    "    Padrão: Em um valor específico no Eixo X (por exemplo, quando o valor da feature é 0.5), você vê os pontos dispersos verticalmente (ou seja, diferentes Valores SHAP).\n",
    "\n",
    "    Conclusão: Isso indica que, mesmo com o mesmo valor para a feature de interesse, seu impacto na previsão muda dependendo dos valores de outras features no modelo (as que você não está colorindo). O efeito é complexo e está sendo influenciado por interações de ordem superior que o modelo capturou.\n",
    "\n",
    "O Dependence Plot é uma ferramenta poderosa para validar se o modelo está aprendendo relações que fazem sentido no domínio do problema. Por exemplo, se uma relação linear é esperada e o gráfico mostra uma relação não linear, isso sugere que a Rede Neural descobriu uma dinâmica mais sutil nos dados. \n",
    "\n",
    "## Interpretação do gráfico gerado\n",
    "\n",
    "- O modelo aprendeu uma relação quase linear para essa feature, onde a contribuição marginal é mais significativa nas extremidades. Os Valores SHAP nulos na faixa intermediária da feature indicam que, nesse ponto, o efeito da feature sobre a previsão é neutro, ou seja, ele não contribui nem positivamente nem negativamente em relação à previsão média do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a89ac64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fdf85d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capacitacao-DnesvXxz-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
