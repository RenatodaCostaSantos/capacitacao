{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Aplicando os modelos no conjunto de teste\n",
    "\n",
    "## Pré-processa dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    root_mean_squared_error,\n",
    ")\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selecionadas\n",
    "\n",
    "caminho_features_selecionadas_all_features = (\n",
    "    \"../data/08_reporting/selected_features_all_features.npy\"\n",
    ")\n",
    "\n",
    "caminho_features_selecionadas_non_linear_features = (\n",
    "    \"../data/08_reporting/selected_non_linear_features.npy\"\n",
    ")\n",
    "\n",
    "caminho_features_selecionadas_linear_features = (\n",
    "    \"../data/08_reporting/selected_linear_features.npy\"\n",
    ")\n",
    "\n",
    "# Caso os dvalores shapa já estejam calculados\n",
    "\n",
    "caminho_shap_all_features = (\n",
    "    \"../data/08_reporting/shap_values_calculados_all_features.npy\"\n",
    ")\n",
    "\n",
    "caminho_shap_non_linear_features = \"../data/08_reporting/shap_values_calculados.npy\"\n",
    "\n",
    "caminho_shap_linear_features = (\n",
    "    \"../data/08_reporting/shap_values_calculados_linear_features.npy\"\n",
    ")\n",
    "\n",
    "# Conjunto de treino normalizado para plotar o gráfico\n",
    "\n",
    "caminho_X_train_all_features = \"../data/03_primary/X_train_all_features.npy\"\n",
    "\n",
    "caminho_X_train_non_linear_features = (\n",
    "    \"../data/03_primary/X_train_non_linear_features.npy\"\n",
    ")\n",
    "\n",
    "caminho_X_train_linear_features = \"../data/03_primary/X_train_linear_features.npy\"\n",
    "\n",
    "# Target de treino normalizado\n",
    "\n",
    "caminho_y_train_all_features = \"../data/03_primary/y_train_all_features.npy\"\n",
    "\n",
    "caminho_y_train_non_linear_features = (\n",
    "    \"../data/03_primary/y_train_non_linear_features.npy\"\n",
    ")\n",
    "\n",
    "caminho_y_train_linear_features = \"../data/03_primary/y_train_linear_features.npy\"\n",
    "\n",
    "# Conjunto de teste normalizado para plotar o gráfico\n",
    "\n",
    "caminho_X_test_shap_all_features = (\n",
    "    \"../data/03_primary/X_test_final_para_shap_all_features.npy\"\n",
    ")\n",
    "\n",
    "caminho_X_test_shap_non_linear_features = (\n",
    "    \"../data/03_primary/X_test_final_para_shap.npy\"\n",
    ")\n",
    "\n",
    "caminho_X_test_shap_linear_features = (\n",
    "    \"../data/03_primary/X_test_final_para_shap_linear_features.npy\"\n",
    ")\n",
    "\n",
    "# Target de teste normalizado\n",
    "\n",
    "caminho_y_teste_normalizado = \"../data/03_primary/y_teste_normalizado.npy\"\n",
    "\n",
    "\n",
    "# shap explainers\n",
    "\n",
    "caminho_explainer_all_features = (\n",
    "    \"../data/08_reporting/explainer_expected_value_all_features.pkl\"\n",
    ")\n",
    "\n",
    "caminho_explainer_non_linear_features = (\n",
    "    \"../data/08_reporting/explainer_expected_value.pkl\"\n",
    ")\n",
    "\n",
    "caminho_explainer_linear_features = (\n",
    "    \"../data/08_reporting/explainer_expected_value_linear_features.pkl\"\n",
    ")\n",
    "\n",
    "# modelos\n",
    "\n",
    "caminho_modelo_all_features = \"../data/06_models/modelo_notebook_2_all_data.joblib\"\n",
    "\n",
    "caminho_modelo_non_linear_features = \"../data/06_models/modelo_notebook_3.joblib\"\n",
    "\n",
    "caminho_modelo_linear_features = \"../data/06_models/modelo_notebook_4.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.read_csv(\"../data/02_intermediate/teste_b_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = teste.drop(columns=[\"r\"])\n",
    "y_test = teste[\"r\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Criando features extras\n",
    "\n",
    "Todas as features criadas para treinar o modelo devem também ser criadas ao se aplicar os dados de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = utils.cria_feature_media_ponderada(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Criando o MinMaxScaler\n",
    "\n",
    "- O `MinMaxScaler` é ajustado (`fit`) no conjunto de treino para aprender os valores de Mínimo e Máximo. O **mesmo scaler ajustado** é então usado para **transformar** o conjunto de teste e garantir a coerência na escala dos dados.\n",
    "\n",
    "- Ajustar o scaler nos dados de teste criaria um **Vazamento de Dados (*Data Leakage*)**, pois o modelo teria acesso, indiretamente, à distribuição dos dados que deveriam ser inéditos, levando a uma avaliação de desempenho irrealista e otimista demais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = pd.read_csv(\"../data/02_intermediate/training_b_df.csv\")\n",
    "\n",
    "X_train = treino.drop(columns=[\"r\"])\n",
    "y_train = treino[\"r\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Escalonamento das Features (X)\n",
    "X_scaler = MinMaxScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "\n",
    "# 2. Escalonamento do Target (Y), se for Regressão Contínua\n",
    "# Reformatar y_train para que o scaler funcione (de Series para 2D array/DataFrame)\n",
    "y_train_2d = y_train.values.reshape(-1, 1)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Aplicando o MinMaxScaler() no target\n",
    "\n",
    "- Para as visualizações das métricas dos modelos, precisa-se aplicar o scaler no target apenas uma vez.\n",
    "\n",
    "- Abaixo aplica-se o y_scaler nos dados de teste e os salva para sua utilização no notebook de 6_Explicabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalonamento do Target (Y)\n",
    "# Reformatar y_train para que o scaler funcione (de Series para 2D array/DataFrame)\n",
    "y_test_2d = y_test.values.reshape(-1, 1)\n",
    "y_test_scaled = y_scaler.fit_transform(y_test_2d)\n",
    "\n",
    "np.save(caminho_y_teste_normalizado, y_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# 1 - Modelo com todas as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checa se o arquivo foi salvo corretamente\n",
    "with open(caminho_features_selecionadas_all_features, \"rb\") as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "\n",
    "selected_feature_names = loaded_data[\"list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all_features = X_test[selected_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = X_scaler.fit_transform(X_test_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 1.2 - Salvando valores normalizados\n",
    "\n",
    "As features normalizadas serão necessárias no notebook de explicabilidade dos modelos, por isso salva-se abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(caminho_X_test_shap_all_features, X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# 1.3 - Inferência "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento do modelo (usando o caminho verificado)\n",
    "best_nn_model = joblib.load(caminho_modelo_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A previsão é feita na escala Z-Score (escalada)\n",
    "y_pred_test_scaled = best_nn_model.predict(X_test_scaled).reshape(-1, 1)\n",
    "\n",
    "# Faz a transformação inversa para obter os valores em 'r':\n",
    "y_pred_test_original = y_scaler.inverse_transform(y_pred_test_scaled)\n",
    "\n",
    "\n",
    "print(\"Previsão no Conjunto de Teste concluída com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_scaled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_original.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_original.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## 1. 4 - Métricas e visualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo das 3 Métricas de Avaliação Finais:\n",
    "mse_test = mean_squared_error(y_test_2d, y_pred_test_original)\n",
    "rmse_test = root_mean_squared_error(y_test_2d, y_pred_test_original)\n",
    "mae_test = mean_absolute_error(y_test_2d, y_pred_test_original)\n",
    "r2_test = r2_score(y_test_2d, y_pred_test_original)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"AVALIAÇÃO DE DESEMPENHO NO CONJUNTO DE TESTE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE (Erro Quadrático Médio): {mse_test:.8f}\")\n",
    "print(f\"RMSE (Erro Absoluto Médio):   {rmse_test:.8f} (Erro médio na unidade de 'r')\")\n",
    "print(f\"MAE (Erro Absoluto Médio):   {mae_test:.8f} (Erro médio na unidade de 'r')\")\n",
    "print(f\"R2 (Ajuste):                 {r2_test:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie a linha de identidade X=Y\n",
    "min_val = min(y_test_2d.min(), y_pred_test_original.min())\n",
    "max_val = max(y_test_2d.max(), y_pred_test_original.max())\n",
    "ideal_line = np.linspace(min_val, max_val, 100)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# 1. Scatter Plot dos Resultados\n",
    "plt.scatter(y_test_2d, y_pred_test_original, alpha=0.6, s=20, label=\"Previsões\")\n",
    "\n",
    "# 2. Linha de Identidade (Ajuste Perfeito)\n",
    "plt.plot(\n",
    "    ideal_line,\n",
    "    ideal_line,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"Ajuste Perfeito (Y=X)\",\n",
    ")\n",
    "\n",
    "plt.title(f\"Previsões vs. Valores Reais de r (R² Final: {r2_test:.4f})\", fontsize=14)\n",
    "plt.xlabel(\"Valores Reais de r\", fontsize=12)\n",
    "plt.ylabel(\"Valores Previstos de r\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\":\", alpha=0.7)\n",
    "plt.gca().set_aspect(\n",
    "    \"equal\", adjustable=\"box\"\n",
    ")  # Garante que os eixos tenham a mesma escala\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule os resíduos (True - Predicted)\n",
    "residuals = y_test_2d - y_pred_test_original\n",
    "\n",
    "# Achata o array para 1D (o formato (N,))\n",
    "residuals_1d = residuals.ravel()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Histograma dos resíduos\n",
    "plt.hist(residuals_1d, bins=30, edgecolor=\"black\", alpha=0.7)\n",
    "\n",
    "# Linha vertical em zero (onde o centro do histograma deveria estar)\n",
    "plt.axvline(x=0, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Erro Zero\")\n",
    "\n",
    "plt.title(\"Distribuição dos Resíduos (Erros)\", fontsize=14)\n",
    "plt.xlabel(\"Resíduo (Real r - Previsto r)\", fontsize=12)\n",
    "plt.ylabel(\"Frequência\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\":\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## 1.4.1 - Visualização com barra de erros\n",
    "\n",
    "Os dados utilizados associam 10 valores diferentes das features a um mesmo valor do target. O objetivo é simular os ruídos presentes em observações astronômicas.\n",
    "\n",
    "A visualização com barras de erros também é feita abaixo utilizando-se os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um DataFrame para facilitar a agregação\n",
    "# Garantindo que y_train e y_pred_original são 1D para o DataFrame\n",
    "y_test_flat = y_test_2d.ravel()\n",
    "y_pred_test_flat = y_pred_test_original.ravel()\n",
    "\n",
    "df_results = pd.DataFrame({\"y_test\": y_test_flat, \"y_test_pred\": y_pred_test_flat})\n",
    "\n",
    "# AGREGAR: Agrupar por 'y_true' e calcular Média e Desvio Padrão para 'y_pred'\n",
    "# 'y_true' (a variável agrupada) será o índice do novo DataFrame\n",
    "df_grouped = (\n",
    "    df_results.groupby(\"y_test\")[\"y_test_pred\"].agg([\"mean\", \"std\"]).reset_index()\n",
    ")\n",
    "\n",
    "# Renomear as colunas para clareza\n",
    "df_grouped.columns = [\"y_test\", \"y_test_pred_mean\", \"y_test_pred_std\"]\n",
    "\n",
    "# Cálculo do Resíduo Padronizado (em módulos, conforme solicitado)\n",
    "# Evite a divisão por zero, substituindo desvios padrão zero por um valor pequeno (ex: 1e-6)\n",
    "df_grouped[\"y_test_pred_std_safe\"] = df_grouped[\"y_test_pred_std\"].replace(0, 1e-6)\n",
    "df_grouped[\"Standardized_Residual\"] = (\n",
    "    np.abs(df_grouped[\"y_test\"] - df_grouped[\"y_test_pred_mean\"])\n",
    "    / df_grouped[\"y_test_pred_std_safe\"]\n",
    ")\n",
    "\n",
    "# Exibir o resultado da agregação (opcional)\n",
    "print(\"Dados Agrupados (Exemplo):\")\n",
    "print(df_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VISUALIZAÇÃO COM GRÁFICO DE DUPLO EIXO ---\n",
    "# Cria um espaço de figuras com 2 linhas e 1 coluna, compartilhando o eixo X\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    2,\n",
    "    1,\n",
    "    figsize=(8, 10),\n",
    "    sharex=True,  # Os dois gráficos compartilham o mesmo eixo X\n",
    "    gridspec_kw={\"hspace\": 0.05},  # Reduz o espaço entre os subplots\n",
    "    constrained_layout=True,\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# GRÁFICO SUPERIOR: Previsão Média vs. Real (Com Barras de Erro)\n",
    "# ==========================================================\n",
    "\n",
    "# 1. Plotar os pontos agregados com Barras de Erro\n",
    "ax1.errorbar(\n",
    "    x=df_grouped[\"y_test\"],\n",
    "    y=df_grouped[\"y_test_pred_mean\"],\n",
    "    yerr=df_grouped[\"y_test_pred_std\"],\n",
    "    fmt=\"o\",\n",
    "    capsize=4,\n",
    "    alpha=0.7,\n",
    "    label=\"Previsão Média ± 1 DP\",\n",
    ")\n",
    "\n",
    "# 2. Linha de Identidade (Ajuste Perfeito Y=X)\n",
    "ax1.plot(\n",
    "    ideal_line,\n",
    "    ideal_line,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"Ajuste Perfeito (Y=X)\",\n",
    ")\n",
    "\n",
    "ax1.set_title(f\"Análise de Previsão Agregada (R² Final: {r2_test:.4f})\", fontsize=14)\n",
    "ax1.set_ylabel(\"Valores Previstos Médios de r\", fontsize=12)\n",
    "ax1.grid(True, linestyle=\":\", alpha=0.7)\n",
    "ax1.legend()\n",
    "\n",
    "# ==========================================================\n",
    "# GRÁFICO INFERIOR: Resíduos Padronizados\n",
    "# ==========================================================\n",
    "\n",
    "# 1. Scatter Plot dos Resíduos Padronizados\n",
    "ax2.scatter(\n",
    "    df_grouped[\"y_test\"],\n",
    "    df_grouped[\"Standardized_Residual\"],\n",
    "    alpha=0.7,\n",
    "    s=30,\n",
    "    label=\"|Resíduo| / DP\",\n",
    ")\n",
    "\n",
    "# 2. Linha de Referência Crítica (Z-Score = 1.0)\n",
    "ax2.axhline(\n",
    "    y=1.0, color=\"red\", linestyle=\"-\", linewidth=2, label=\"Limite de 1 Desvio Padrão\"\n",
    ")\n",
    "ax2.axhline(y=2.0, color=\"orange\", linestyle=\"--\", linewidth=1, label=\"Limite de 2 DP\")\n",
    "\n",
    "\n",
    "ax2.set_xlabel(\"Valores Reais de r(Y_true)\", fontsize=12)\n",
    "ax2.set_ylabel(\"Resíduo Padronizado (|Y - Ŷ| / DP)\", fontsize=12)\n",
    "ax2.grid(True, linestyle=\":\", alpha=0.7)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "# 2 - Modelo com seleção de features não linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## 2.1 - Selecionando features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checa se o arquivo foi salvo corretamente\n",
    "with open(caminho_features_selecionadas_non_linear_features, \"rb\") as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "\n",
    "selected_feature_names = loaded_data[\"list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_non_linear_selection = X_test[selected_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = X_scaler.fit_transform(X_test_non_linear_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## 3.2 - Salvando valores normalizados\n",
    "\n",
    "As features normalizadas serão necessárias no notebook de explicabilidade dos modelos, por isso salva-se abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(caminho_X_test_shap_non_linear_features, X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "# 3.3 - Inferência "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento do modelo (usando o caminho verificado)\n",
    "best_nn_model = joblib.load(caminho_modelo_non_linear_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A previsão é feita na escala Z-Score (escalada)\n",
    "y_pred_test_scaled = best_nn_model.predict(X_test_scaled).reshape(-1, 1)\n",
    "\n",
    "# Faz a transformação inversa para obter os valores em 'r':\n",
    "y_pred_test_original = y_scaler.inverse_transform(y_pred_test_scaled)\n",
    "\n",
    "\n",
    "print(\"Previsão no Conjunto de Teste concluída com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_scaled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_original.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_original.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "## 3. 4 - Métricas e visualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo das 3 Métricas de Avaliação Finais:\n",
    "mse_test = mean_squared_error(y_test_2d, y_pred_test_original)\n",
    "rmse_test = root_mean_squared_error(y_test_2d, y_pred_test_original)\n",
    "mae_test = mean_absolute_error(y_test_2d, y_pred_test_original)\n",
    "r2_test = r2_score(y_test_2d, y_pred_test_original)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"AVALIAÇÃO DE DESEMPENHO NO CONJUNTO DE TESTE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE (Erro Quadrático Médio): {mse_test:.8f}\")\n",
    "print(f\"RMSE (Erro Absoluto Médio):   {rmse_test:.8f} (Erro médio na unidade de 'r')\")\n",
    "print(f\"MAE (Erro Absoluto Médio):   {mae_test:.8f} (Erro médio na unidade de 'r')\")\n",
    "print(f\"R2 (Ajuste):                 {r2_test:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie a linha de identidade X=Y\n",
    "min_val = min(y_test_2d.min(), y_pred_test_original.min())\n",
    "max_val = max(y_test_2d.max(), y_pred_test_original.max())\n",
    "ideal_line = np.linspace(min_val, max_val, 100)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# 1. Scatter Plot dos Resultados\n",
    "plt.scatter(y_test_2d, y_pred_test_original, alpha=0.6, s=20, label=\"Previsões\")\n",
    "\n",
    "# 2. Linha de Identidade (Ajuste Perfeito)\n",
    "plt.plot(\n",
    "    ideal_line,\n",
    "    ideal_line,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"Ajuste Perfeito (Y=X)\",\n",
    ")\n",
    "\n",
    "plt.title(f\"Previsões vs. Valores Reais de r (R² Final: {r2_test:.4f})\", fontsize=14)\n",
    "plt.xlabel(\"Valores Reais de r\", fontsize=12)\n",
    "plt.ylabel(\"Valores Previstos de r\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\":\", alpha=0.7)\n",
    "plt.gca().set_aspect(\n",
    "    \"equal\", adjustable=\"box\"\n",
    ")  # Garante que os eixos tenham a mesma escala\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule os resíduos (True - Predicted)\n",
    "residuals = y_test_2d - y_pred_test_original\n",
    "\n",
    "# Achata o array para 1D (o formato (N,))\n",
    "residuals_1d = residuals.ravel()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Histograma dos resíduos\n",
    "plt.hist(residuals_1d, bins=30, edgecolor=\"black\", alpha=0.7)\n",
    "\n",
    "# Linha vertical em zero (onde o centro do histograma deveria estar)\n",
    "plt.axvline(x=0, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Erro Zero\")\n",
    "\n",
    "plt.title(\"Distribuição dos Resíduos (Erros)\", fontsize=14)\n",
    "plt.xlabel(\"Resíduo (Real r - Previsto r)\", fontsize=12)\n",
    "plt.ylabel(\"Frequência\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\":\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "## 3.4.1 - Visualização com barra de erros\n",
    "\n",
    "Os dados utilizados associam 10 valores diferentes das features a um mesmo valor do target. O objetivo é simular os ruídos presentes em observações astronômicas.\n",
    "\n",
    "A visualização com barras de erros também é feita abaixo utilizando-se os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um DataFrame para facilitar a agregação\n",
    "# Garantindo que y_train e y_pred_original são 1D para o DataFrame\n",
    "y_test_flat = y_test_2d.ravel()\n",
    "y_pred_test_flat = y_pred_test_original.ravel()\n",
    "\n",
    "df_results = pd.DataFrame({\"y_test\": y_test_flat, \"y_test_pred\": y_pred_test_flat})\n",
    "\n",
    "# AGREGAR: Agrupar por 'y_true' e calcular Média e Desvio Padrão para 'y_pred'\n",
    "# 'y_true' (a variável agrupada) será o índice do novo DataFrame\n",
    "df_grouped = (\n",
    "    df_results.groupby(\"y_test\")[\"y_test_pred\"].agg([\"mean\", \"std\"]).reset_index()\n",
    ")\n",
    "\n",
    "# Renomear as colunas para clareza\n",
    "df_grouped.columns = [\"y_test\", \"y_test_pred_mean\", \"y_test_pred_std\"]\n",
    "\n",
    "# Cálculo do Resíduo Padronizado (em módulos, conforme solicitado)\n",
    "# Evite a divisão por zero, substituindo desvios padrão zero por um valor pequeno (ex: 1e-6)\n",
    "df_grouped[\"y_test_pred_std_safe\"] = df_grouped[\"y_test_pred_std\"].replace(0, 1e-6)\n",
    "df_grouped[\"Standardized_Residual\"] = (\n",
    "    np.abs(df_grouped[\"y_test\"] - df_grouped[\"y_test_pred_mean\"])\n",
    "    / df_grouped[\"y_test_pred_std_safe\"]\n",
    ")\n",
    "\n",
    "# Exibir o resultado da agregação (opcional)\n",
    "print(\"Dados Agrupados (Exemplo):\")\n",
    "print(df_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VISUALIZAÇÃO COM GRÁFICO DE DUPLO EIXO ---\n",
    "# Cria um espaço de figuras com 2 linhas e 1 coluna, compartilhando o eixo X\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    2,\n",
    "    1,\n",
    "    figsize=(8, 10),\n",
    "    sharex=True,  # Os dois gráficos compartilham o mesmo eixo X\n",
    "    gridspec_kw={\"hspace\": 0.05},  # Reduz o espaço entre os subplots\n",
    "    constrained_layout=True,\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# GRÁFICO SUPERIOR: Previsão Média vs. Real (Com Barras de Erro)\n",
    "# ==========================================================\n",
    "\n",
    "# 1. Plotar os pontos agregados com Barras de Erro\n",
    "ax1.errorbar(\n",
    "    x=df_grouped[\"y_test\"],\n",
    "    y=df_grouped[\"y_test_pred_mean\"],\n",
    "    yerr=df_grouped[\"y_test_pred_std\"],\n",
    "    fmt=\"o\",\n",
    "    capsize=4,\n",
    "    alpha=0.7,\n",
    "    label=\"Previsão Média ± 1 DP\",\n",
    ")\n",
    "\n",
    "# 2. Linha de Identidade (Ajuste Perfeito Y=X)\n",
    "ax1.plot(\n",
    "    ideal_line,\n",
    "    ideal_line,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"Ajuste Perfeito (Y=X)\",\n",
    ")\n",
    "\n",
    "ax1.set_title(f\"Análise de Previsão Agregada (R² Final: {r2_test:.4f})\", fontsize=14)\n",
    "ax1.set_ylabel(\"Valores Previstos Médios de r\", fontsize=12)\n",
    "ax1.grid(True, linestyle=\":\", alpha=0.7)\n",
    "ax1.legend()\n",
    "\n",
    "# ==========================================================\n",
    "# GRÁFICO INFERIOR: Resíduos Padronizados\n",
    "# ==========================================================\n",
    "\n",
    "# 1. Scatter Plot dos Resíduos Padronizados\n",
    "ax2.scatter(\n",
    "    df_grouped[\"y_test\"],\n",
    "    df_grouped[\"Standardized_Residual\"],\n",
    "    alpha=0.7,\n",
    "    s=30,\n",
    "    label=\"|Resíduo| / DP\",\n",
    ")\n",
    "\n",
    "# 2. Linha de Referência Crítica (Z-Score = 1.0)\n",
    "ax2.axhline(\n",
    "    y=1.0, color=\"red\", linestyle=\"-\", linewidth=2, label=\"Limite de 1 Desvio Padrão\"\n",
    ")\n",
    "ax2.axhline(y=2.0, color=\"orange\", linestyle=\"--\", linewidth=1, label=\"Limite de 2 DP\")\n",
    "\n",
    "\n",
    "ax2.set_xlabel(\"Valores Reais de r(Y_true)\", fontsize=12)\n",
    "ax2.set_ylabel(\"Resíduo Padronizado (|Y - Ŷ| / DP)\", fontsize=12)\n",
    "ax2.grid(True, linestyle=\":\", alpha=0.7)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "# 3 - Modelo com seleção linear de features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "## 3.1 - Selecionando features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checa se o arquivo foi salvo corretamente\n",
    "with open(caminho_features_selecionadas_linear_features, \"rb\") as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "\n",
    "selected_feature_names = loaded_data[\"list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_linear_selection = X_test[selected_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = X_scaler.fit_transform(X_test_linear_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "## 3.2 - Salvando valores normalizados\n",
    "\n",
    "As features normalizadas serão necessárias no notebook de explicabilidade dos modelos, por isso salva-se abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(caminho_X_test_shap_linear_features, X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "# 3.3 - Inferência "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento do modelo (usando o caminho verificado)\n",
    "best_nn_model = joblib.load(caminho_modelo_linear_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A previsão é feita na escala Z-Score (escalada)\n",
    "y_pred_test_scaled = best_nn_model.predict(X_test_scaled).reshape(-1, 1)\n",
    "\n",
    "# Faz a transformação inversa para obter os valores em 'r':\n",
    "y_pred_test_original = y_scaler.inverse_transform(y_pred_test_scaled)\n",
    "\n",
    "\n",
    "print(\"Previsão no Conjunto de Teste concluída com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_scaled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_original.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_original.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "## 3. 4 - Métricas e visualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo das 3 Métricas de Avaliação Finais:\n",
    "mse_test = mean_squared_error(y_test_2d, y_pred_test_original)\n",
    "rmse_test = root_mean_squared_error(y_test_2d, y_pred_test_original)\n",
    "mae_test = mean_absolute_error(y_test_2d, y_pred_test_original)\n",
    "r2_test = r2_score(y_test_2d, y_pred_test_original)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"AVALIAÇÃO DE DESEMPENHO NO CONJUNTO DE TESTE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE (Erro Quadrático Médio): {mse_test:.8f}\")\n",
    "print(f\"RMSE (Erro Absoluto Médio):   {rmse_test:.8f} (Erro médio na unidade de 'r')\")\n",
    "print(f\"MAE (Erro Absoluto Médio):   {mae_test:.8f} (Erro médio na unidade de 'r')\")\n",
    "print(f\"R2 (Ajuste):                 {r2_test:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie a linha de identidade X=Y\n",
    "min_val = min(y_test_2d.min(), y_pred_test_original.min())\n",
    "max_val = max(y_test_2d.max(), y_pred_test_original.max())\n",
    "ideal_line = np.linspace(min_val, max_val, 100)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# 1. Scatter Plot dos Resultados\n",
    "plt.scatter(y_test_2d, y_pred_test_original, alpha=0.6, s=20, label=\"Previsões\")\n",
    "\n",
    "# 2. Linha de Identidade (Ajuste Perfeito)\n",
    "plt.plot(\n",
    "    ideal_line,\n",
    "    ideal_line,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"Ajuste Perfeito (Y=X)\",\n",
    ")\n",
    "\n",
    "plt.title(f\"Previsões vs. Valores Reais de r (R² Final: {r2_test:.4f})\", fontsize=14)\n",
    "plt.xlabel(\"Valores Reais de r\", fontsize=12)\n",
    "plt.ylabel(\"Valores Previstos de r\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\":\", alpha=0.7)\n",
    "plt.gca().set_aspect(\n",
    "    \"equal\", adjustable=\"box\"\n",
    ")  # Garante que os eixos tenham a mesma escala\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule os resíduos (True - Predicted)\n",
    "residuals = y_test_2d - y_pred_test_original\n",
    "\n",
    "# Achata o array para 1D (o formato (N,))\n",
    "residuals_1d = residuals.ravel()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Histograma dos resíduos\n",
    "plt.hist(residuals_1d, bins=30, edgecolor=\"black\", alpha=0.7)\n",
    "\n",
    "# Linha vertical em zero (onde o centro do histograma deveria estar)\n",
    "plt.axvline(x=0, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Erro Zero\")\n",
    "\n",
    "plt.title(\"Distribuição dos Resíduos (Erros)\", fontsize=14)\n",
    "plt.xlabel(\"Resíduo (Real r - Previsto r)\", fontsize=12)\n",
    "plt.ylabel(\"Frequência\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\":\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "## 3.4.1 - Visualização com barra de erros\n",
    "\n",
    "Os dados utilizados associam 10 valores diferentes das features a um mesmo valor do target. O objetivo é simular os ruídos presentes em observações astronômicas.\n",
    "\n",
    "A visualização com barras de erros também é feita abaixo utilizando-se os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um DataFrame para facilitar a agregação\n",
    "# Garantindo que y_train e y_pred_original são 1D para o DataFrame\n",
    "y_test_flat = y_test_2d.ravel()\n",
    "y_pred_test_flat = y_pred_test_original.ravel()\n",
    "\n",
    "df_results = pd.DataFrame({\"y_test\": y_test_flat, \"y_test_pred\": y_pred_test_flat})\n",
    "\n",
    "# AGREGAR: Agrupar por 'y_true' e calcular Média e Desvio Padrão para 'y_pred'\n",
    "# 'y_true' (a variável agrupada) será o índice do novo DataFrame\n",
    "df_grouped = (\n",
    "    df_results.groupby(\"y_test\")[\"y_test_pred\"].agg([\"mean\", \"std\"]).reset_index()\n",
    ")\n",
    "\n",
    "# Renomear as colunas para clareza\n",
    "df_grouped.columns = [\"y_test\", \"y_test_pred_mean\", \"y_test_pred_std\"]\n",
    "\n",
    "# Cálculo do Resíduo Padronizado (em módulos, conforme solicitado)\n",
    "# Evite a divisão por zero, substituindo desvios padrão zero por um valor pequeno (ex: 1e-6)\n",
    "df_grouped[\"y_test_pred_std_safe\"] = df_grouped[\"y_test_pred_std\"].replace(0, 1e-6)\n",
    "df_grouped[\"Standardized_Residual\"] = (\n",
    "    np.abs(df_grouped[\"y_test\"] - df_grouped[\"y_test_pred_mean\"])\n",
    "    / df_grouped[\"y_test_pred_std_safe\"]\n",
    ")\n",
    "\n",
    "# Exibir o resultado da agregação (opcional)\n",
    "print(\"Dados Agrupados (Exemplo):\")\n",
    "print(df_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VISUALIZAÇÃO COM GRÁFICO DE DUPLO EIXO ---\n",
    "# Cria um espaço de figuras com 2 linhas e 1 coluna, compartilhando o eixo X\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    2,\n",
    "    1,\n",
    "    figsize=(8, 10),\n",
    "    sharex=True,  # Os dois gráficos compartilham o mesmo eixo X\n",
    "    gridspec_kw={\"hspace\": 0.05},  # Reduz o espaço entre os subplots\n",
    "    constrained_layout=True,\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# GRÁFICO SUPERIOR: Previsão Média vs. Real (Com Barras de Erro)\n",
    "# ==========================================================\n",
    "\n",
    "# 1. Plotar os pontos agregados com Barras de Erro\n",
    "ax1.errorbar(\n",
    "    x=df_grouped[\"y_test\"],\n",
    "    y=df_grouped[\"y_test_pred_mean\"],\n",
    "    yerr=df_grouped[\"y_test_pred_std\"],\n",
    "    fmt=\"o\",\n",
    "    capsize=4,\n",
    "    alpha=0.7,\n",
    "    label=\"Previsão Média ± 1 DP\",\n",
    ")\n",
    "\n",
    "# 2. Linha de Identidade (Ajuste Perfeito Y=X)\n",
    "ax1.plot(\n",
    "    ideal_line,\n",
    "    ideal_line,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"Ajuste Perfeito (Y=X)\",\n",
    ")\n",
    "\n",
    "ax1.set_title(f\"Análise de Previsão Agregada (R² Final: {r2_test:.4f})\", fontsize=14)\n",
    "ax1.set_ylabel(\"Valores Previstos Médios de r\", fontsize=12)\n",
    "ax1.grid(True, linestyle=\":\", alpha=0.7)\n",
    "ax1.legend()\n",
    "\n",
    "# ==========================================================\n",
    "# GRÁFICO INFERIOR: Resíduos Padronizados\n",
    "# ==========================================================\n",
    "\n",
    "# 1. Scatter Plot dos Resíduos Padronizados\n",
    "ax2.scatter(\n",
    "    df_grouped[\"y_test\"],\n",
    "    df_grouped[\"Standardized_Residual\"],\n",
    "    alpha=0.7,\n",
    "    s=30,\n",
    "    label=\"|Resíduo| / DP\",\n",
    ")\n",
    "\n",
    "# 2. Linha de Referência Crítica (Z-Score = 1.0)\n",
    "ax2.axhline(\n",
    "    y=1.0, color=\"red\", linestyle=\"-\", linewidth=2, label=\"Limite de 1 Desvio Padrão\"\n",
    ")\n",
    "ax2.axhline(y=2.0, color=\"orange\", linestyle=\"--\", linewidth=1, label=\"Limite de 2 DP\")\n",
    "\n",
    "\n",
    "ax2.set_xlabel(\"Valores Reais de r(Y_true)\", fontsize=12)\n",
    "ax2.set_ylabel(\"Resíduo Padronizado (|Y - Ŷ| / DP)\", fontsize=12)\n",
    "ax2.grid(True, linestyle=\":\", alpha=0.7)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "# 4 - Sugestões para trabalhos futuros\n",
    "\n",
    "- Criar novas features com os dados de entrada.\n",
    "\n",
    "- Aumentar a rede de parâmetros da validação cruzada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capacitacao-DnesvXxz-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
