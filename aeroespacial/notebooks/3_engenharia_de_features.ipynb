{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42948c34",
   "metadata": {},
   "source": [
    "# Engenharia e seleção de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7725989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 10:36:25.841562: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-24 10:36:25.871204: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-24 10:36:26.816183: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib #Para salvar o modelo \n",
    "from sklearn.experimental import enable_halving_search_cv # Necessário para importar\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import Input\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import uniform, randint # Para a distribuição de parâmetros\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import os, random\n",
    "import utils\n",
    "from functools import partial\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deefbd2",
   "metadata": {},
   "source": [
    "# Observações:\n",
    "\n",
    "1 - As bibliotecas que serão usadas neste projeto possuem fontes múltiplas de aleatoriedade. Por isso ressalta-se os seguintes pontos abaixo:\n",
    "\n",
    "- numpy, random (do Python), e tensorflow usam geradores diferentes.\n",
    "\n",
    "    - Fixar random_state em HalvingRandomSearchCV só controla o sorteio dos hiperparâmetros, não o comportamento interno da rede.\n",
    "\n",
    "- TensorFlow e paralelismo introduzem aleatóriedade.\n",
    "\n",
    "    - Por padrão, TensorFlow usa múltiplas threads e kernels otimizados (como cuDNN no GPU), que executam operações não determinísticas (principalmente Dropout e Dense).\n",
    "\n",
    "- O KerasRegressor recria o modelo a cada chamada\n",
    "\n",
    "    - Mesmo que o random_state do scikit-learn esteja fixo, cada vez que fit() é chamado, o Sequential() do TensorFlow usa um estado de aleatoriedade independente (a menos que se fixe isso manualmente dentro da função que cria o modelo).\n",
    "\n",
    "Dadas as observações acima, fixa-se abaixo o parâmetro SEED para alguns métodos que serão utilizados neste notebook.\n",
    "\n",
    "\n",
    "\n",
    "2 - Ao rodar o processo de criação do modelo, na minha máquina, com o parâmetro n_jobs diferente de 1, havia o seguinte warning:\n",
    "\n",
    "   \n",
    "    UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak. \n",
    "   \n",
    "\n",
    "- Ao parar, todo o processo de seleção de parâmetros ótimos era comprometido e não havia reproducibilidade do modelo à cada rodada.\n",
    "\n",
    "- Colocando o n_jobs = 1, garante-se a reproducibilidade do modelo, ao custo de aumentar bastante o tempo de treinamento do modelo\n",
    "\n",
    "- Caso esse modelo seja rodado em uma máquina mais robusta, esse problema pode não ocorrer, sendo possível acelerar o tempo de treinamento ao mudar-se o valor do parâmetro n_jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e3c880",
   "metadata": {},
   "source": [
    "# Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6794026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desativar GPU (garante total determinismo)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# Fixar sementes globais\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Garante execução determinística, desativando otimizações não reprodutíveis\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "\n",
    "\n",
    "# Numero de neuronios de entrada na rede neural\n",
    "neuronios_entrada = 30\n",
    "\n",
    "n_jobs = 1\n",
    "\n",
    "# Caso queira-se reaproveitar o cálculo (demorado) dos valores do shap e investigar apenas a explicabilidade do modelo\n",
    "existing_model_shap = False\n",
    "\n",
    "caminho_features_selecionadas = '../data/08_reporting/selected_non_linear_features.npy'\n",
    "\n",
    "caminho_dados = '../data/02_intermediate/training_b_df.csv'\n",
    "\n",
    "caminho_modelo = '../data/06_models/modelo_notebook_3.joblib'\n",
    "\n",
    "caminho_shap = '../data/08_reporting/shap_values_calculados.npy'\n",
    "\n",
    "caminho_X_train_non_linear_features = '../data/03_primary/X_train_non_linear_features.npy'\n",
    "\n",
    "caminho_y_train_non_linear_features = '../data/03_primary/y_train_non_linear_features.npy'\n",
    "\n",
    "caminho_X_test_shap_non_linear_features = '../data/03_primary/X_test_final_para_shap.npy'\n",
    "\n",
    "caminho_y_test_shap_non_linear_features = '../data/03_primary/y_test_final_para_shap.npy'\n",
    "\n",
    "caminho_explainer = '../data/08_reporting/explainer_expected_value.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bcd2f",
   "metadata": {},
   "source": [
    "# 1 - Lendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79504538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(caminho_dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234afd5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a5c7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(columns=['r'])\n",
    "y_train = df['r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b269011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_2</th>\n",
       "      <th>l_3</th>\n",
       "      <th>l_4</th>\n",
       "      <th>l_5</th>\n",
       "      <th>l_6</th>\n",
       "      <th>l_7</th>\n",
       "      <th>l_8</th>\n",
       "      <th>l_9</th>\n",
       "      <th>l_10</th>\n",
       "      <th>l_11</th>\n",
       "      <th>...</th>\n",
       "      <th>l_502</th>\n",
       "      <th>l_503</th>\n",
       "      <th>l_504</th>\n",
       "      <th>l_505</th>\n",
       "      <th>l_506</th>\n",
       "      <th>l_507</th>\n",
       "      <th>l_508</th>\n",
       "      <th>l_509</th>\n",
       "      <th>l_510</th>\n",
       "      <th>l_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.490171e-10</td>\n",
       "      <td>6.058483e-10</td>\n",
       "      <td>6.123373e-10</td>\n",
       "      <td>5.492230e-10</td>\n",
       "      <td>4.987756e-10</td>\n",
       "      <td>4.996063e-10</td>\n",
       "      <td>4.873860e-10</td>\n",
       "      <td>4.858634e-10</td>\n",
       "      <td>3.759005e-10</td>\n",
       "      <td>4.054609e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>...</td>\n",
       "      <td>6.590990e-10</td>\n",
       "      <td>5.957533e-10</td>\n",
       "      <td>5.382490e-10</td>\n",
       "      <td>5.511306e-10</td>\n",
       "      <td>4.965663e-10</td>\n",
       "      <td>4.848698e-10</td>\n",
       "      <td>4.638441e-10</td>\n",
       "      <td>4.146040e-10</td>\n",
       "      <td>3.850935e-10</td>\n",
       "      <td>3.658829e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>...</td>\n",
       "      <td>6.345819e-10</td>\n",
       "      <td>6.044535e-10</td>\n",
       "      <td>5.756162e-10</td>\n",
       "      <td>5.306156e-10</td>\n",
       "      <td>4.744517e-10</td>\n",
       "      <td>4.625054e-10</td>\n",
       "      <td>4.354919e-10</td>\n",
       "      <td>3.960931e-10</td>\n",
       "      <td>3.977156e-10</td>\n",
       "      <td>3.608611e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>6.901658e-10</td>\n",
       "      <td>6.067260e-10</td>\n",
       "      <td>5.923192e-10</td>\n",
       "      <td>5.206132e-10</td>\n",
       "      <td>5.064276e-10</td>\n",
       "      <td>4.546328e-10</td>\n",
       "      <td>4.771503e-10</td>\n",
       "      <td>4.041781e-10</td>\n",
       "      <td>3.925857e-10</td>\n",
       "      <td>3.493796e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>7.062580e-10</td>\n",
       "      <td>6.144698e-10</td>\n",
       "      <td>5.878574e-10</td>\n",
       "      <td>5.581525e-10</td>\n",
       "      <td>5.349131e-10</td>\n",
       "      <td>4.615936e-10</td>\n",
       "      <td>4.710612e-10</td>\n",
       "      <td>4.277015e-10</td>\n",
       "      <td>3.812178e-10</td>\n",
       "      <td>3.678812e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>6.431329e-10</td>\n",
       "      <td>5.715559e-10</td>\n",
       "      <td>5.597664e-10</td>\n",
       "      <td>5.280729e-10</td>\n",
       "      <td>5.106220e-10</td>\n",
       "      <td>4.678772e-10</td>\n",
       "      <td>4.277167e-10</td>\n",
       "      <td>4.167436e-10</td>\n",
       "      <td>3.841709e-10</td>\n",
       "      <td>3.595660e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>...</td>\n",
       "      <td>6.537801e-10</td>\n",
       "      <td>5.945880e-10</td>\n",
       "      <td>5.588835e-10</td>\n",
       "      <td>5.163429e-10</td>\n",
       "      <td>4.827139e-10</td>\n",
       "      <td>4.791565e-10</td>\n",
       "      <td>4.352070e-10</td>\n",
       "      <td>4.263153e-10</td>\n",
       "      <td>3.777479e-10</td>\n",
       "      <td>3.572270e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>...</td>\n",
       "      <td>6.520265e-10</td>\n",
       "      <td>6.202956e-10</td>\n",
       "      <td>5.871600e-10</td>\n",
       "      <td>5.503659e-10</td>\n",
       "      <td>5.109527e-10</td>\n",
       "      <td>4.832764e-10</td>\n",
       "      <td>4.629816e-10</td>\n",
       "      <td>4.468772e-10</td>\n",
       "      <td>4.371018e-10</td>\n",
       "      <td>3.820512e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>...</td>\n",
       "      <td>6.219886e-10</td>\n",
       "      <td>5.591386e-10</td>\n",
       "      <td>5.611786e-10</td>\n",
       "      <td>5.009329e-10</td>\n",
       "      <td>5.056176e-10</td>\n",
       "      <td>4.515758e-10</td>\n",
       "      <td>4.394383e-10</td>\n",
       "      <td>4.093147e-10</td>\n",
       "      <td>3.904380e-10</td>\n",
       "      <td>3.585950e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>...</td>\n",
       "      <td>6.071864e-10</td>\n",
       "      <td>5.726886e-10</td>\n",
       "      <td>5.989801e-10</td>\n",
       "      <td>4.690192e-10</td>\n",
       "      <td>4.894000e-10</td>\n",
       "      <td>4.265101e-10</td>\n",
       "      <td>4.466181e-10</td>\n",
       "      <td>3.627355e-10</td>\n",
       "      <td>3.940726e-10</td>\n",
       "      <td>3.365828e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           l_2       l_3       l_4       l_5       l_6       l_7       l_8  \\\n",
       "0     0.000172  0.000066  0.000078  0.000069  0.000063  0.000021  0.000053   \n",
       "1     0.000058  0.000068  0.000118  0.000045  0.000045  0.000043  0.000063   \n",
       "2     0.000066  0.000086  0.000129  0.000044  0.000056  0.000038  0.000041   \n",
       "3     0.000140  0.000167  0.000060  0.000070  0.000064  0.000030  0.000018   \n",
       "4     0.000025  0.000066  0.000041  0.000060  0.000052  0.000034  0.000046   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7995  0.000138  0.000049  0.000021  0.000019  0.000019  0.000039  0.000031   \n",
       "7996  0.000049  0.000049  0.000023  0.000023  0.000052  0.000026  0.000055   \n",
       "7997  0.000084  0.000028  0.000024  0.000038  0.000044  0.000050  0.000049   \n",
       "7998  0.000007  0.000125  0.000024  0.000012  0.000050  0.000034  0.000055   \n",
       "7999  0.000085  0.000047  0.000044  0.000050  0.000027  0.000007  0.000039   \n",
       "\n",
       "           l_9      l_10      l_11  ...         l_502         l_503  \\\n",
       "0     0.000031  0.000043  0.000060  ...  6.490171e-10  6.058483e-10   \n",
       "1     0.000035  0.000042  0.000061  ...  6.590990e-10  5.957533e-10   \n",
       "2     0.000059  0.000060  0.000048  ...  6.345819e-10  6.044535e-10   \n",
       "3     0.000049  0.000025  0.000042  ...  6.901658e-10  6.067260e-10   \n",
       "4     0.000031  0.000035  0.000084  ...  7.062580e-10  6.144698e-10   \n",
       "...        ...       ...       ...  ...           ...           ...   \n",
       "7995  0.000039  0.000046  0.000054  ...  6.431329e-10  5.715559e-10   \n",
       "7996  0.000036  0.000066  0.000094  ...  6.537801e-10  5.945880e-10   \n",
       "7997  0.000026  0.000089  0.000078  ...  6.520265e-10  6.202956e-10   \n",
       "7998  0.000085  0.000079  0.000103  ...  6.219886e-10  5.591386e-10   \n",
       "7999  0.000040  0.000049  0.000081  ...  6.071864e-10  5.726886e-10   \n",
       "\n",
       "             l_504         l_505         l_506         l_507         l_508  \\\n",
       "0     6.123373e-10  5.492230e-10  4.987756e-10  4.996063e-10  4.873860e-10   \n",
       "1     5.382490e-10  5.511306e-10  4.965663e-10  4.848698e-10  4.638441e-10   \n",
       "2     5.756162e-10  5.306156e-10  4.744517e-10  4.625054e-10  4.354919e-10   \n",
       "3     5.923192e-10  5.206132e-10  5.064276e-10  4.546328e-10  4.771503e-10   \n",
       "4     5.878574e-10  5.581525e-10  5.349131e-10  4.615936e-10  4.710612e-10   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "7995  5.597664e-10  5.280729e-10  5.106220e-10  4.678772e-10  4.277167e-10   \n",
       "7996  5.588835e-10  5.163429e-10  4.827139e-10  4.791565e-10  4.352070e-10   \n",
       "7997  5.871600e-10  5.503659e-10  5.109527e-10  4.832764e-10  4.629816e-10   \n",
       "7998  5.611786e-10  5.009329e-10  5.056176e-10  4.515758e-10  4.394383e-10   \n",
       "7999  5.989801e-10  4.690192e-10  4.894000e-10  4.265101e-10  4.466181e-10   \n",
       "\n",
       "             l_509         l_510         l_511  \n",
       "0     4.858634e-10  3.759005e-10  4.054609e-10  \n",
       "1     4.146040e-10  3.850935e-10  3.658829e-10  \n",
       "2     3.960931e-10  3.977156e-10  3.608611e-10  \n",
       "3     4.041781e-10  3.925857e-10  3.493796e-10  \n",
       "4     4.277015e-10  3.812178e-10  3.678812e-10  \n",
       "...            ...           ...           ...  \n",
       "7995  4.167436e-10  3.841709e-10  3.595660e-10  \n",
       "7996  4.263153e-10  3.777479e-10  3.572270e-10  \n",
       "7997  4.468772e-10  4.371018e-10  3.820512e-10  \n",
       "7998  4.093147e-10  3.904380e-10  3.585950e-10  \n",
       "7999  3.627355e-10  3.940726e-10  3.365828e-10  \n",
       "\n",
       "[8000 rows x 510 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99c620fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.002872\n",
       "1       0.002872\n",
       "2       0.002872\n",
       "3       0.002872\n",
       "4       0.002872\n",
       "          ...   \n",
       "7995    0.011467\n",
       "7996    0.011467\n",
       "7997    0.011467\n",
       "7998    0.011467\n",
       "7999    0.011467\n",
       "Name: r, Length: 8000, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed5e64",
   "metadata": {},
   "source": [
    "# 2 - Engenharia de features\n",
    "\n",
    "Ao conversar com a astrofísica Camila Novaes que forneceu os dados simulados estudados aqui, foi sugerida a criação da média ponderada abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4f2d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras 5 linhas com a nova feature:\n",
      "        l_2       l_3       l_4         l_511  media_ponderada_Cls\n",
      "0  0.000172  0.000066  0.000078  4.054609e-10             0.000100\n",
      "1  0.000058  0.000068  0.000118  3.658829e-10             0.000100\n",
      "2  0.000066  0.000086  0.000129  3.608611e-10             0.000098\n",
      "3  0.000140  0.000167  0.000060  3.493796e-10             0.000100\n",
      "4  0.000025  0.000066  0.000041  3.678812e-10             0.000099\n"
     ]
    }
   ],
   "source": [
    "X_train = utils.cria_feature_media_ponderada(X_train)\n",
    "\n",
    "print(\"Primeiras 5 linhas com a nova feature:\")\n",
    "print(X_train[['l_2', 'l_3', 'l_4', 'l_511', 'media_ponderada_Cls']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24c7d2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['media_ponderada_Cls'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c89aa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7995    0.000096\n",
       "7996    0.000095\n",
       "7997    0.000096\n",
       "7998    0.000096\n",
       "7999    0.000096\n",
       "Name: media_ponderada_Cls, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['media_ponderada_Cls'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8cbd4a",
   "metadata": {},
   "source": [
    "# 3 - Seleção de features\n",
    "\n",
    "Para a seleção de features utiliza-se o seguinte fluxo:\n",
    "\n",
    "1 - Utiliza-se o método SelectKBest do scikit-learn para se verificar correlações não-lineares.\n",
    "\n",
    "2 - Mantém-se apenas as 30 features mais importantes.\n",
    "\n",
    "3 - Verifica-se o desempenho da rede neural no conjunto de teste utilizando-se apenas as features selecionadas e compara-se com o desempenho obtido utilizando-se todas as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35852578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selecionadas: Index(['l_46', 'l_49', 'l_50', 'l_51', 'l_52', 'l_53', 'l_54', 'l_55', 'l_56',\n",
      "       'l_57', 'l_58', 'l_59', 'l_60', 'l_61', 'l_62', 'l_63', 'l_64', 'l_65',\n",
      "       'l_66', 'l_67', 'l_68', 'l_69', 'l_70', 'l_71', 'l_72', 'l_73', 'l_74',\n",
      "       'l_76', 'l_78', 'l_79'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 1. Instanciar o seletor. Exemplo: K=150 seleciona as 150 melhores features.\n",
    "k_best = SelectKBest(score_func=f_regression, k=neuronios_entrada)\n",
    "\n",
    "# 2. Ajustar o seletor aos dados de TREINO (X e y)\n",
    "k_best.fit(X_train, y_train.to_numpy().ravel())\n",
    "\n",
    "# 3. Obter os scores e os índices das colunas selecionadas\n",
    "scores = k_best.scores_\n",
    "selected_features_indices = k_best.get_support(indices=True)\n",
    "selected_feature_names = X_train.columns[selected_features_indices]\n",
    "\n",
    "print(\"Features Selecionadas:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a54f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[selected_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64318718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_46</th>\n",
       "      <th>l_49</th>\n",
       "      <th>l_50</th>\n",
       "      <th>l_51</th>\n",
       "      <th>l_52</th>\n",
       "      <th>l_53</th>\n",
       "      <th>l_54</th>\n",
       "      <th>l_55</th>\n",
       "      <th>l_56</th>\n",
       "      <th>l_57</th>\n",
       "      <th>...</th>\n",
       "      <th>l_68</th>\n",
       "      <th>l_69</th>\n",
       "      <th>l_70</th>\n",
       "      <th>l_71</th>\n",
       "      <th>l_72</th>\n",
       "      <th>l_73</th>\n",
       "      <th>l_74</th>\n",
       "      <th>l_76</th>\n",
       "      <th>l_78</th>\n",
       "      <th>l_79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.001310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.001520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.001855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          l_46      l_49      l_50      l_51      l_52      l_53      l_54  \\\n",
       "0     0.000568  0.000638  0.000701  0.000771  0.000818  0.000873  0.000939   \n",
       "1     0.000654  0.000674  0.000796  0.000699  0.000746  0.000764  0.000700   \n",
       "2     0.000686  0.000759  0.000848  0.000829  0.000722  0.000922  0.000624   \n",
       "3     0.000684  0.000823  0.000610  0.000728  0.000669  0.000669  0.000792   \n",
       "4     0.000610  0.000698  0.000833  0.000617  0.000628  0.000808  0.001126   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7995  0.000939  0.000773  0.001052  0.000995  0.001159  0.000861  0.001198   \n",
       "7996  0.000816  0.000750  0.001073  0.000823  0.001088  0.000985  0.001058   \n",
       "7997  0.000833  0.001187  0.001032  0.000987  0.001257  0.000964  0.001439   \n",
       "7998  0.000874  0.000941  0.001029  0.000807  0.001165  0.001144  0.001026   \n",
       "7999  0.000871  0.000903  0.001042  0.000956  0.000819  0.001201  0.000964   \n",
       "\n",
       "          l_55      l_56      l_57  ...      l_68      l_69      l_70  \\\n",
       "0     0.000982  0.001126  0.001015  ...  0.000984  0.001099  0.001259   \n",
       "1     0.000949  0.001216  0.000904  ...  0.001127  0.001154  0.001106   \n",
       "2     0.000913  0.000878  0.000778  ...  0.001336  0.000972  0.000976   \n",
       "3     0.000812  0.000808  0.000908  ...  0.001123  0.001047  0.001010   \n",
       "4     0.000699  0.000922  0.000794  ...  0.000938  0.001098  0.001235   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7995  0.001034  0.001244  0.000946  ...  0.001309  0.001294  0.001486   \n",
       "7996  0.001175  0.001289  0.000915  ...  0.001372  0.001428  0.001231   \n",
       "7997  0.001035  0.001091  0.001000  ...  0.001417  0.001614  0.001439   \n",
       "7998  0.000871  0.001350  0.001025  ...  0.001460  0.001139  0.001482   \n",
       "7999  0.001091  0.001297  0.001140  ...  0.001397  0.001034  0.001280   \n",
       "\n",
       "          l_71      l_72      l_73      l_74      l_76      l_78      l_79  \n",
       "0     0.001331  0.001318  0.001067  0.001064  0.001141  0.001255  0.001310  \n",
       "1     0.001562  0.001213  0.001350  0.001044  0.001049  0.001164  0.001508  \n",
       "2     0.001167  0.001118  0.000939  0.001145  0.001117  0.001375  0.001520  \n",
       "3     0.001157  0.001151  0.001276  0.001350  0.001094  0.001166  0.001469  \n",
       "4     0.001110  0.001324  0.001548  0.001396  0.001211  0.001416  0.001078  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7995  0.001566  0.001065  0.001847  0.001348  0.001532  0.001613  0.001543  \n",
       "7996  0.001482  0.001654  0.001557  0.001487  0.001449  0.001570  0.001266  \n",
       "7997  0.001508  0.001674  0.001615  0.001207  0.001757  0.001353  0.001465  \n",
       "7998  0.001604  0.001239  0.001308  0.001372  0.001445  0.001678  0.001590  \n",
       "7999  0.001332  0.001779  0.001284  0.001679  0.001358  0.001511  0.001855  \n",
       "\n",
       "[8000 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bbeaac",
   "metadata": {},
   "source": [
    "## Observação\n",
    "\n",
    "Para plotar os gráficos SHAP com a explicabilidade dos modelos, salva-se abaixo as features usadas na modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52afc217",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acafa6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['l_46', 'l_49', 'l_50', 'l_51', 'l_52', 'l_53', 'l_54', 'l_55', 'l_56',\n",
       "       'l_57', 'l_58', 'l_59', 'l_60', 'l_61', 'l_62', 'l_63', 'l_64', 'l_65',\n",
       "       'l_66', 'l_67', 'l_68', 'l_69', 'l_70', 'l_71', 'l_72', 'l_73', 'l_74',\n",
       "       'l_76', 'l_78', 'l_79'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6fa026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(caminho_features_selecionadas, 'wb') as f:\n",
    "    pickle.dump({'list': selected_features}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "356ab4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checa se o arquivo foi salvo corretamente\n",
    "with open(caminho_features_selecionadas, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a869127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['l_46', 'l_49', 'l_50', 'l_51', 'l_52', 'l_53', 'l_54', 'l_55', 'l_56',\n",
       "       'l_57', 'l_58', 'l_59', 'l_60', 'l_61', 'l_62', 'l_63', 'l_64', 'l_65',\n",
       "       'l_66', 'l_67', 'l_68', 'l_69', 'l_70', 'l_71', 'l_72', 'l_73', 'l_74',\n",
       "       'l_76', 'l_78', 'l_79'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data['list']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c221dd5",
   "metadata": {},
   "source": [
    "## 4 - Normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae07d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Escalonamento das Features (X) \n",
    "X_scaler = MinMaxScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "\n",
    "# 2. Escalonamento do Target (Y), se for Regressão Contínua \n",
    "# Reformatar y_train para que o scaler funcione (de Series para 2D array/DataFrame)\n",
    "y_train_2d = y_train.values.reshape(-1, 1)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fb184d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07814483, 0.09171029, 0.11424122, ..., 0.09764745, 0.12867018,\n",
       "        0.13565379],\n",
       "       [0.10799935, 0.10428419, 0.14492683, ..., 0.07307275, 0.1033187 ,\n",
       "        0.18997513],\n",
       "       [0.11893827, 0.13401595, 0.16133722, ..., 0.0912086 , 0.16242003,\n",
       "        0.19308172],\n",
       "       ...,\n",
       "       [0.17016362, 0.28404317, 0.22044892, ..., 0.26230991, 0.15624684,\n",
       "        0.17809298],\n",
       "       [0.18425042, 0.1976455 , 0.21934742, ..., 0.17903084, 0.24753763,\n",
       "        0.21235507],\n",
       "       [0.18315856, 0.18459088, 0.22365973, ..., 0.15579902, 0.20070543,\n",
       "        0.28505451]], shape=(8000, 30))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "367aa1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0000000000000002)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86a28453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21cd3f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1800591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3936f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0526217",
   "metadata": {},
   "source": [
    "## Salvando valores normalizados\n",
    "\n",
    "As features normalizadas serão necessárias no notebook de explicabilidade dos modelos, por isso salva-se abaixo:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cff659c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(caminho_X_train_non_linear_features, X_train_scaled)\n",
    "\n",
    "np.save(caminho_y_train_non_linear_features, y_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193b9a9c",
   "metadata": {},
   "source": [
    "# 4 - Construindo um modelo de redes neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma função que já “fixa” neuronios_entrada\n",
    "modelo_com_input = partial(utils.criar_modelo_regularizado, neuronios_entrada=neuronios_entrada)\n",
    "\n",
    "# 1. Distribuição de Parâmetros a serem testados (ranges ao invés de listas fixas)\n",
    "param_distributions = {\n",
    "    # Neurônios: número inteiro aleatório entre 32 e 256\n",
    "    'model__neurons': randint(low=32, high=256), \n",
    "    \n",
    "    # Taxa de Aprendizado: valor contínuo aleatório em escala logarítmica\n",
    "    # Ex: entre 1e-4 e 1e-2 (0.0001 e 0.01)\n",
    "    'model__learning_rate': uniform(loc=0.0001, scale=0.0099), \n",
    "    \n",
    "    # Batch Size: valores discretos\n",
    "    'batch_size': [16, 32, 64],\n",
    "\n",
    "    # O dropout_rate ajuda a diminuir o overfitting\n",
    "    'model__dropout_rate': uniform(loc=0.1, scale=0.4), # Testar entre 10% e 50%\n",
    "    \n",
    "    # Epochs: valores discretos (o HRS vai descartar os piores cedo)\n",
    "    'epochs': [5, 10, 20] \n",
    "}\n",
    "\n",
    "# 2. Configurar o KerasRegressor\n",
    "nn_model = KerasRegressor(model=modelo_com_input, \n",
    "                          verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf86eac",
   "metadata": {},
   "source": [
    "## Atenção\n",
    "\n",
    "- Ao juntar as features com o target, foram colocadas 10 simulações associadas ao mesmo target. \n",
    "\n",
    "- Ao usar a validação cruzada é preciso ter certeza de que as linhas associadas a um dado valor do target, caiam tanto na validação quanto no treino, evitando assim o vazamento do target. \n",
    "\n",
    "- Para isso utiliza-se o parâmetro `cv=gkf` no HalvingRandomSearch abaixo.\n",
    "\n",
    "- A variável gkf usa a classe GroupKFold para levar em consideração a observação acima e evitar o vazamento do target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aba083",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = y_train.to_numpy().ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b96a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb8fb9",
   "metadata": {},
   "source": [
    "Abaixo, verifica-se se realmente não há vazamento de target usando-se o GrupoKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialize o GroupKFold\n",
    "gkf = GroupKFold(n_splits=5) \n",
    "\n",
    "# Itere sobre os splits (apenas a primeira dobra é suficiente para checar)\n",
    "for fold, (train_index, val_index) in enumerate(gkf.split(X_train, y_train, groups=groups)):\n",
    "    \n",
    "    if fold == 0: # Checar apenas o primeiro fold\n",
    "        \n",
    "        # 1. Obter os valores de 'r' (originais, não escalados) para Treino e Validação\n",
    "        r_train_fold = y_train[train_index].to_numpy().ravel()\n",
    "        r_val_fold = y_train[val_index].to_numpy().ravel()\n",
    "        \n",
    "        # 2. Encontrar os valores ÚNICOS de 'r' em cada conjunto\n",
    "        r_unique_train = set(r_train_fold)\n",
    "        r_unique_val = set(r_val_fold)\n",
    "        \n",
    "        # 3. Encontrar a Interseção (os valores vazados)\n",
    "        vazamentos = r_unique_train.intersection(r_unique_val)\n",
    "        \n",
    "        print(f\"--- Checagem do Fold {fold + 1} ---\")\n",
    "        print(f\"Total de valores únicos de 'r' no Treino: {len(r_unique_train)}\")\n",
    "        print(f\"Total de valores únicos de 'r' na Validação: {len(r_unique_val)}\")\n",
    "        print(f\"Valores de 'r' vazando (Interseção): {len(vazamentos)}\")\n",
    "        \n",
    "        if len(vazamentos) == 0:\n",
    "            print(\"✅ GroupKFold está funcionando corretamente: Nenhuma intersecção de valores de 'r'.\")\n",
    "        else:\n",
    "            print(f\"❌ ERRO GRAVE: {len(vazamentos)} valores de 'r' estão vazando! O GroupKFold falhou na divisão dos grupos.\")\n",
    "            print(f\"Valores vazados (Primeiros 5): {list(vazamentos)[:5]}\")\n",
    "            \n",
    "        break # Parar após o primeiro fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e035a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# factor=2: Descarta metade dos candidatos a cada iteração.\n",
    "# candidates: O número total de combinações que serão testadas na 1ª rodada (a maior).\n",
    "hrs = HalvingRandomSearchCV(\n",
    "    estimator=nn_model, \n",
    "    param_distributions=param_distributions, \n",
    "    factor=2, \n",
    "    n_candidates=50,\n",
    "    scoring='r2', \n",
    "    random_state=42,\n",
    "    cv=gkf, \n",
    "    verbose=2,\n",
    "    n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "print(\"Iniciando Halving Random Search (Testando as melhores combinações eficientemente)...\")\n",
    "\n",
    "# 4. Executar a busca\n",
    "# O HRS executa a busca e o retreinamento (refit=True)\n",
    "hrs_result = hrs.fit(X_train_scaled, y_train_scaled, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d0f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESULTADOS FINAIS DO HALVING RANDOM SEARCH\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f'Número de features usadas: {len(selected_feature_names)}')\n",
    "\n",
    "# Melhor pontuação\n",
    "print(f\"Melhor R² Médio: {hrs_result.best_score_:.4f}\")\n",
    "\n",
    "# Melhor combinação de hiperparâmetros\n",
    "print(\"Melhores Parâmetros:\")\n",
    "print(hrs_result.best_params_)\n",
    "\n",
    "# Obter o melhor modelo treinado\n",
    "best_nn_model = hrs_result.best_estimator_\n",
    "\n",
    "# Salva o  modelo gerado\n",
    "joblib.dump(best_nn_model, caminho_modelo)\n",
    "\n",
    "# --- AVALIAÇÃO FINAL ---\n",
    "\n",
    "\n",
    "# O reshape é necessário pois o KerasRegressor.predict() retorna 1D por padrão no Scikit-Learn Wrapper\n",
    "y_pred_scaled = best_nn_model.predict(X_train_scaled).reshape(-1, 1)\n",
    "\n",
    "# Faz a transformação inversa para obter os valores em 'r':\n",
    "y_pred_original = y_scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# 4. Prepara o target verdadeiro para comparação. Garante que y_train seja convertido de um pandas Series para um Numpy array, que é o objeto que sai da inverse_transform acima\n",
    "y_true = y_train.values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "# Cálculo das métricas no conjunto de treino\n",
    "final_mse = mean_squared_error(y_true, y_pred_original) \n",
    "final_rmse = root_mean_squared_error(y_true, y_pred_original) \n",
    "final_r2 = r2_score(y_true, y_pred_original)\n",
    "final_mae = mean_absolute_error(y_true, y_pred_original) \n",
    "\n",
    "\n",
    "print(\"\\nMétricas do Melhor Modelo (Avaliadas nos dados completos de Treino):\")\n",
    "print(f\"  MSE (Erro Quadrático Médio): {final_mse:.8f} (Penaliza erros grandes)\")\n",
    "print(f\"  RMSE (Erro Quadrático Médio): {final_rmse:.8f} (Penaliza erros grandes)\")\n",
    "print(f\"  MAE (Erro Absoluto Médio):   {final_mae:.8f} (Unidade de 'r')\")\n",
    "print(f\"  R2 (Ajuste):                 {final_r2:.4f} (Qualidade do ajuste)\")\n",
    "print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c67575",
   "metadata": {},
   "source": [
    "## Observação\n",
    "\n",
    "- Comparado com os resultados nos dados de treino do notebook 2, todas as métricas melhoraram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c643255",
   "metadata": {},
   "source": [
    "## 4.1 - Visualizando os resultados\n",
    "\n",
    "Abaixo, são mostradas duas visualizações:\n",
    "\n",
    "- A distribuição dos valores preditos comparados com os reais,\n",
    "\n",
    "- A distribuição dos resíduos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad166a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf29544",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_original.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbcb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Suponha que você já tem:\n",
    "# y_true_original: valores verdadeiros de 'r' (na escala original)\n",
    "# y_pred_original: valores previstos de 'r' (na escala original)\n",
    "\n",
    "# Crie a linha de identidade X=Y\n",
    "min_val = min(y_train.min(), y_pred_original.min())\n",
    "max_val = max(y_train.max(), y_pred_original.max())\n",
    "ideal_line = np.linspace(min_val, max_val, 100)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# 1. Scatter Plot dos Resultados\n",
    "plt.scatter(y_train, y_pred_original, alpha=0.6, s=20, label='Previsões')\n",
    "\n",
    "# 2. Linha de Identidade (Ajuste Perfeito)\n",
    "plt.plot(ideal_line, ideal_line, color='red', linestyle='--', linewidth=2, label='Ajuste Perfeito (Y=X)')\n",
    "\n",
    "plt.title(f'Previsões vs. Valores Reais de r (R² Final: {final_r2:.4f})', fontsize=14)\n",
    "plt.xlabel('Valores Reais de r', fontsize=12)\n",
    "plt.ylabel('Valores Previstos de r', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.7)\n",
    "plt.gca().set_aspect('equal', adjustable='box') # Garante que os eixos tenham a mesma escala\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule os resíduos (True - Predicted)\n",
    "residuals = y_true - y_pred_original\n",
    "\n",
    "# Achata o array para 1D (o formato (N,))\n",
    "residuals_1d = residuals.ravel()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Histograma dos resíduos\n",
    "plt.hist(residuals_1d, bins=30, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Linha vertical em zero (onde o centro do histograma deveria estar)\n",
    "plt.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Erro Zero')\n",
    "\n",
    "plt.title('Distribuição dos Resíduos (Erros)', fontsize=14)\n",
    "plt.xlabel('Resíduo (Real r - Previsto r)', fontsize=12)\n",
    "plt.ylabel('Frequência', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREPARAÇÃO ---\n",
    "# Criando um DataFrame para facilitar a agregação\n",
    "# Garantindo que y_train e y_pred_original são 1D para o DataFrame\n",
    "y_true_flat = y_true.ravel()\n",
    "y_pred_flat = y_pred_original.ravel()\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'y_true': y_true_flat,\n",
    "    'y_pred': y_pred_flat\n",
    "})\n",
    "\n",
    "# AGREGAR: Agrupar por 'y_true' e calcular Média e Desvio Padrão para 'y_pred'\n",
    "# 'y_true' (a variável agrupada) será o índice do novo DataFrame\n",
    "df_grouped = df_results.groupby('y_true')['y_pred'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Renomear as colunas para clareza\n",
    "df_grouped.columns = ['y_true', 'y_pred_mean', 'y_pred_std']\n",
    "\n",
    "\n",
    "# Cálculo do Resíduo Padronizado (em módulos, conforme solicitado)\n",
    "# Evite a divisão por zero, substituindo desvios padrão zero por um valor pequeno (ex: 1e-6)\n",
    "df_grouped['y_pred_std_safe'] = df_grouped['y_pred_std'].replace(0, 1e-6)\n",
    "df_grouped['Standardized_Residual'] = (\n",
    "    np.abs(df_grouped['y_true'] - df_grouped['y_pred_mean']) / df_grouped['y_pred_std_safe']\n",
    ")\n",
    "\n",
    "# Exibir o resultado da agregação (opcional)\n",
    "print(\"Dados Agrupados (Exemplo):\")\n",
    "print(df_grouped.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1797cc",
   "metadata": {},
   "source": [
    "## Visualização com barra de erros\n",
    "\n",
    "Os dados utilizados associam 10 valores diferentes das features a um mesmo valor do target. O objetivo é simular os ruídos presentes em observações astronômicas.\n",
    "\n",
    "Uma forma mais útil de visualizar os dados é portanto colapsar os 10 dados referentes à cada valor do target em seu valor médio e desvio padrão.\n",
    "\n",
    "Além disso, plota-se gráfico de resíduos padronizados, que ajuda  visualizar o número de observações que se distanciam do valor real em mais de um desvio-padrão.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d4aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um espaço de figuras com 2 linhas e 1 coluna, compartilhando o eixo X\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    2, 1, \n",
    "    figsize=(8, 10), \n",
    "    sharex=True, # Os dois gráficos compartilham o mesmo eixo X\n",
    "    gridspec_kw={'hspace': 0.05}, # Reduz o espaço entre os subplots\n",
    "    constrained_layout=True \n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# GRÁFICO SUPERIOR: Previsão Média vs. Real (Com Barras de Erro)\n",
    "# ==========================================================\n",
    "\n",
    "# 1. Plotar os pontos agregados com Barras de Erro\n",
    "ax1.errorbar(\n",
    "    x=df_grouped['y_true'],             \n",
    "    y=df_grouped['y_pred_mean'],            \n",
    "    yerr=df_grouped['y_pred_std'],          \n",
    "    fmt='o',                                \n",
    "    capsize=4,                              \n",
    "    alpha=0.7,\n",
    "    label='Previsão Média ± 1 DP'\n",
    ")\n",
    "\n",
    "# 2. Linha de Identidade (Ajuste Perfeito Y=X)\n",
    "ax1.plot(ideal_line, ideal_line, color='red', linestyle='--', linewidth=2, label='Ajuste Perfeito (Y=X)')\n",
    "\n",
    "ax1.set_title(f'Análise de Previsão Agregada (R² Final: {final_r2:.4f})', fontsize=14)\n",
    "ax1.set_ylabel('Valores Previstos Médios de r', fontsize=12)\n",
    "ax1.grid(True, linestyle=':', alpha=0.7)\n",
    "ax1.legend()\n",
    "\n",
    "# ==========================================================\n",
    "# GRÁFICO INFERIOR: Resíduos Padronizados\n",
    "# ==========================================================\n",
    "\n",
    "# 1. Scatter Plot dos Resíduos Padronizados\n",
    "ax2.scatter(\n",
    "    df_grouped['y_true'], \n",
    "    df_grouped['Standardized_Residual'], \n",
    "    alpha=0.7, \n",
    "    s=30, \n",
    "    label='|Resíduo| / DP'\n",
    ")\n",
    "\n",
    "# 2. Linha de Referência Crítica (Z-Score = 1.0)\n",
    "ax2.axhline(\n",
    "    y=1.0, \n",
    "    color='red', \n",
    "    linestyle='-', \n",
    "    linewidth=2, \n",
    "    label='Limite de 1 Desvio Padrão'\n",
    ")\n",
    "ax2.axhline(y=2.0, color='orange', linestyle='--', linewidth=1, label='Limite de 2 DP')\n",
    "\n",
    "\n",
    "ax2.set_xlabel('Valores Reais de r (Y_true)', fontsize=12)\n",
    "ax2.set_ylabel('Resíduo Padronizado (|Y - Ŷ| / DP)', fontsize=12)\n",
    "ax2.grid(True, linestyle=':', alpha=0.7)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7a891a",
   "metadata": {},
   "source": [
    "## Obsevação\n",
    "\n",
    "- Houve uma melhora nas métricas, mas fica evidente nas visualizações acima que houve uma piora nas previsões para valores muito baixo do target 'r'.\n",
    "\n",
    "- O modelo tende a errar mais para valores de r próximos de 0. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capacitacao-DnesvXxz-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
